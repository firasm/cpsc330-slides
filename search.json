[
  {
    "objectID": "slides-09.html#announcements",
    "href": "slides-09.html#announcements",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Announcements",
    "text": "Announcements\n\nLearning Log 02 is now out!\nReminder: HW4 is due Monday night\nReminder: Midterm 1 is this week!"
  },
  {
    "objectID": "slides-09.html#group-work-class-demo-live-coding",
    "href": "slides-09.html#group-work-class-demo-live-coding",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-09.html#ml-workflow",
    "href": "slides-09.html#ml-workflow",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "ML workflow",
    "text": "ML workflow"
  },
  {
    "objectID": "slides-09.html#classification-metrics",
    "href": "slides-09.html#classification-metrics",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Classification Metrics",
    "text": "Classification Metrics\nAt the end of last class we talked about some of the problems with “accuracy”, and we brainstormed some possible alternatives, and saw that there are tonnes of options.\nToday, let’s sift through the noise and develop some intuition about why we need classification metrics, and how some of them are used."
  },
  {
    "objectID": "slides-09.html#example-from-statquest",
    "href": "slides-09.html#example-from-statquest",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Example from StatQuest!",
    "text": "Example from StatQuest!\nLet’s first walk through this example through StatQuest with obese mice and classifying them using Logistic Regression:\n\nSource: StatQuest"
  },
  {
    "objectID": "slides-09.html#activity-1-create-confusion-matrix",
    "href": "slides-09.html#activity-1-create-confusion-matrix",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Activity 1: Create Confusion Matrix",
    "text": "Activity 1: Create Confusion Matrix\n\nSource: StatQuest"
  },
  {
    "objectID": "slides-09.html#activity-2-calculate-precision-recall-specificity",
    "href": "slides-09.html#activity-2-calculate-precision-recall-specificity",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Activity 2: Calculate Precision, Recall, Specificity",
    "text": "Activity 2: Calculate Precision, Recall, Specificity\n\nRecall (aka Sensitivity in biomedical literature)\n\nTP/(TP+FN)\n\nPrecision\n\nTP/(TP+FP)\n\nSpecificity\n\nTN/(TN+FP)"
  },
  {
    "objectID": "slides-09.html#break",
    "href": "slides-09.html#break",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Break!",
    "text": "Break!\nLet’s take a break!"
  },
  {
    "objectID": "slides-09.html#confusion-matrix-questions",
    "href": "slides-09.html#confusion-matrix-questions",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Confusion matrix questions",
    "text": "Confusion matrix questions\nImagine a spam filter model where emails classified as spam are labeled 1 and non-spam emails are labeled 0. If a spam email is incorrectly classified as non-spam, what is this error called?\n\n\nA false positive\n\n\nA true positive\n\n\nA false negative\n\n\nA true negative"
  },
  {
    "objectID": "slides-09.html#confusion-matrix-questions-1",
    "href": "slides-09.html#confusion-matrix-questions-1",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Confusion matrix questions",
    "text": "Confusion matrix questions\nIn an intrusion detection system, intrusions are identified as 1 and non-intrusive activities as 0. If the system fails to identify an actual intrusion, wrongly categorizing it as non-intrusive, what is this type of error called?\n\n\nA false positive\n\n\nA true positive\n\n\nA false negative\n\n\nA true negative"
  },
  {
    "objectID": "slides-09.html#confusion-matrix-questions-2",
    "href": "slides-09.html#confusion-matrix-questions-2",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Confusion matrix questions",
    "text": "Confusion matrix questions\nIn a medical test for a disease, diseased states are labeled as 1 and healthy states as 0. If a healthy patient is incorrectly diagnosed with the disease, what is this error known as?\n\n\nA false positive\n\n\nA true positive\n\n\nA false negative\n\n\nA true negative"
  },
  {
    "objectID": "slides-09.html#iclicker-exercise-9.1",
    "href": "slides-09.html#iclicker-exercise-9.1",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "iClicker Exercise 9.1",
    "text": "iClicker Exercise 9.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIn medical diagnosis, false positives are more damaging than false negatives (assume “positive” means the person has a disease, “negative” means they don’t).\n\n\nIn spam classification, false positives are more damaging than false negatives (assume “positive” means the email is spam, “negative” means they it’s not).\n\n\nIf method A gets a higher accuracy than method B, that means its precision is also higher.\n\n\nIf method A gets a higher accuracy than method B, that means its recall is also higher."
  },
  {
    "objectID": "slides-09.html#counter-examples",
    "href": "slides-09.html#counter-examples",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Counter examples",
    "text": "Counter examples\nMethod A - higher accuracy but lower precision\n\n\n\nNegative\nPositive\n\n\n\n\n90\n5\n\n\n5\n0\n\n\n\nMethod B - lower accuracy but higher precision\n\n\n\nNegative\nPositive\n\n\n\n\n80\n15\n\n\n0\n5"
  },
  {
    "objectID": "slides-09.html#recap-confusion-matrix",
    "href": "slides-09.html#recap-confusion-matrix",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Recap: Confusion matrix",
    "text": "Recap: Confusion matrix\n\n\n\n\n\nTN \\(\\rightarrow\\) True negatives\nFP \\(\\rightarrow\\) False positives\nFN \\(\\rightarrow\\) False negatives\nTP \\(\\rightarrow\\) True positives"
  },
  {
    "objectID": "slides-09.html#recap-precision-recall-f1-score",
    "href": "slides-09.html#recap-precision-recall-f1-score",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Recap: Precision, Recall, F1-Score",
    "text": "Recap: Precision, Recall, F1-Score\n\n\n\n\n\\[ f1 = 2 \\times \\frac{ precision \\times recall}{precision + recall}\\]"
  },
  {
    "objectID": "slides-09.html#recap-pr-curve",
    "href": "slides-09.html#recap-pr-curve",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Recap: PR curve",
    "text": "Recap: PR curve\n\nCalculate precision and recall (TPR) at every possible threshold and graph them.\nBetter choice for highly imbalanced datasets because it focuses on the performance of the positive class."
  },
  {
    "objectID": "slides-09.html#demo-pr-curve",
    "href": "slides-09.html#demo-pr-curve",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Demo: PR curve",
    "text": "Demo: PR curve\nGoogle’s Machine Learning Modules"
  },
  {
    "objectID": "slides-09.html#recap-roc-curve",
    "href": "slides-09.html#recap-roc-curve",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Recap: ROC curve",
    "text": "Recap: ROC curve\n\nCalculate the true positive rate (TPR) and false positive rate (FPR) (\\(\\frac{FP}{FP + TN}\\)) at every possible thresholding and graph TPR over FPR.\nGood choice when the datasets are roughly balanced."
  },
  {
    "objectID": "slides-09.html#recap-roc-curve-1",
    "href": "slides-09.html#recap-roc-curve-1",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Recap: ROC Curve",
    "text": "Recap: ROC Curve\n\nNot a great choice when there is an extreme imbalance because FPR can remain relatively low even if the number of false positives is high, simply because the number of negatives is very large.\n\\[ FPR  = \\frac{FP}{FP + TN}\\]\nThe area under the ROC curve (AUC) represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative."
  },
  {
    "objectID": "slides-09.html#questions-for-you",
    "href": "slides-09.html#questions-for-you",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Questions for you",
    "text": "Questions for you\n\nWhat’s the difference between the average precision (AP) score and F1-score?\nWhich model would you pick?"
  },
  {
    "objectID": "slides-09.html#questions-for-you-1",
    "href": "slides-09.html#questions-for-you-1",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Questions for you",
    "text": "Questions for you\n\n\n\n\n\nWhat’s the AUC of a baseline model?\n\n\nSource"
  },
  {
    "objectID": "slides-09.html#questions-for-you-2",
    "href": "slides-09.html#questions-for-you-2",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Questions for you",
    "text": "Questions for you\n\n\n\n\n\nWhich model would you pick?"
  },
  {
    "objectID": "slides-09.html#iclicker-exercise-9.2",
    "href": "slides-09.html#iclicker-exercise-9.2",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "iClicker Exercise 9.2",
    "text": "iClicker Exercise 9.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIf we increase the classification threshold, both true and false positives are likely to decrease.\n\n\nIf we increase the classification threshold, both true and false negatives are likely to decrease.\n\n\nLowering the classification threshold generally increases the model’s recall.\n\n\n\nRaising the classification threshold can improve the precision of the model if it effectively reduces the number of false positives without significantly affecting true positives."
  },
  {
    "objectID": "slides-09.html#dealing-with-class-imbalance",
    "href": "slides-09.html#dealing-with-class-imbalance",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "Dealing with class imbalance",
    "text": "Dealing with class imbalance\n\nUnder sampling\nOversampling\nclass weight=\"balanced\" (preferred method for this course)\nSMOTE"
  },
  {
    "objectID": "slides-09.html#roc-auc-questions",
    "href": "slides-09.html#roc-auc-questions",
    "title": "CPSC 330 Lecture 9: Classification Metrics",
    "section": "ROC AUC questions",
    "text": "ROC AUC questions\nConsider the points A, B, and C in the following diagram, each representing a threshold. Which threshold would you pick in each scenario?\n\n\n\n\n\n\nIf false positives (false alarms) are highly costly\n\n\nIf false positives are cheap and false negatives (missed true positives) highly costly\n\n\nIf the costs are roughly equivalent\n\n\n\nSource"
  },
  {
    "objectID": "slides-20.html#announcements",
    "href": "slides-20.html#announcements",
    "title": "CPSC 330 Lecture 20: Survival analysis",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides-12.html#scenario-1-which-model-would-you-pick",
    "href": "slides-12.html#scenario-1-which-model-would-you-pick",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Scenario 1: Which model would you pick",
    "text": "Scenario 1: Which model would you pick\nPredicting whether a patient is likely to develop diabetes based on features such as age, blood pressure, glucose levels, and BMI. You have two models:\n\nLGBM which results in 0.9 f1 score\nLogistic regression which results in 0.84 f1 score\n\nWhich model would you pick? Why?"
  },
  {
    "objectID": "slides-12.html#scenario-2",
    "href": "slides-12.html#scenario-2",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Scenario 2",
    "text": "Scenario 2\nPredicting whether a user will purchase a product next based on their browsing history, previous purchases, and click behavior. You have two models:\n\nLGBM which results in 0.9 F1 score\nLogistic regression which results in 0.84 F1 score\n\nWhich model would you pick? Why?"
  },
  {
    "objectID": "slides-12.html#transparency",
    "href": "slides-12.html#transparency",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Transparency",
    "text": "Transparency\n\nIn many domains understanding the relationship between features and predictions is critical for trust and regulatory compliance.\n\nFeature importances\n\nHow does the output depend upon the input?\nHow do the predictions change as a function of a particular feature?"
  },
  {
    "objectID": "slides-12.html#correlations",
    "href": "slides-12.html#correlations",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Correlations",
    "text": "Correlations\n\n\n\n\n\nWhat are some limitations of correlations?"
  },
  {
    "objectID": "slides-12.html#interepreting-coefficients",
    "href": "slides-12.html#interepreting-coefficients",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Interepreting coefficients",
    "text": "Interepreting coefficients\n\nLinear models are interpretable because you get coefficients associated with different features.\nEach coefficient represents the estimated impact of a feature on the target variable, assuming all other features are held constant.\nIn a Ridge model,\n\nA positive coefficient indicates that as the feature’s value increases, the predicted value also increases.\n\nA negative coefficient indicates that an increase in the feature’s value leads to a decrease in the predicted value."
  },
  {
    "objectID": "slides-12.html#interepreting-coefficients-1",
    "href": "slides-12.html#interepreting-coefficients-1",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Interepreting coefficients",
    "text": "Interepreting coefficients\n\nWhen we have different types of preprocessed features, what challenges you might face in interpreting them?\n\nOrdinally encoded features\nOne-hot encoded features\nScaled numeric features"
  },
  {
    "objectID": "slides-12.html#group-work-class-demo-live-coding-if-time-permits",
    "href": "slides-12.html#group-work-class-demo-live-coding-if-time-permits",
    "title": "CPSC 330 Lecture 12: Feature importances",
    "section": "Group Work: Class Demo & Live Coding (if time permits)",
    "text": "Group Work: Class Demo & Live Coding (if time permits)\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today.\n  \nIf you really don’t want to create a repo,\n\nNavigate to the cpsc330-2025S1 repo\nrun git pull to pull the latest files in the course repo\nLook for the demo file here"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Overview",
    "section": "",
    "text": "Title\n\n\n\nDescription\n\n\n\n\n\n\n\n\nLecture 1: Introduction to CPSC 330\n\n\nWhat is machine learning, types of machine learning, learning to navigate through the course materials, getting familiar with the course policies\n\n\n\n\n\n\nLecture 2: Terminology, Baselines, Decision Trees\n\n\nSupervised machine learning terminology: Features, target, examples, training, parameters and hyperparameters, Decision boundary, classification vs. regression, inference vs. prediction, accuracy vs. error, baselines, intuition of decision trees\n\n\n\n\n\n\nLecture 3: ML fundamentals\n\n\ngeneralization, data splitting, overfitting, underfitting, the fundamental tradeoff, the golden rule\n\n\n\n\n\n\nLecture 4: \\(k\\)-nearest neighbours and SVM RBFs\n\n\nintroduction to KNNs, hyperparameter n_neighbours or \\(k\\), C and gamma hyperparameters of SVM RBF, decision boundaries with different values of hyperparameters.\n\n\n\n\n\n\nLecture 5: Preprocessing and sklearn pipelines\n\n\nPre-processing, Transformations, and pipelines.\n\n\n\n\n\n\nLecture 6: Column transformer and text features\n\n\nPreprocessing and sklearn pipelines\n\n\n\n\n\n\nLecture 7: Linear models\n\n\nLinear regression, logistic regression, prediction probabilities, sigmoid, interpretation of coefficients\n\n\n\n\n\n\nCPSC 330 Lecture 8: Hyperparameter Optimization\n\n\nLinear regression, logistic regression, prediction probabilities, sigmoid, interpretation of coefficients\n\n\n\n\n\n\nCPSC 330 Lecture 9: Classification Metrics\n\n\nconfusion metrics, precision, recall, f1-score, PR curves, AP score, ROC curve, ROC AUC, class imbalance\n\n\n\n\n\n\nCPSC 330 Lecture 10: Regression Metrics\n\n\nRegression metrics\n\n\n\n\n\n\nCPSC 330 Lecture 11: Ensembles\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 12: Feature importances\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 13: Feature Engineering and Selection\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 14: K-Means\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 16: Recommender Systems\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 17: Natural Language Processing\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 18: Introduction to deep learning and computer vision\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 19: Time series\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 20: Survival analysis\n\n\n \n\n\n\n\n\n\nCPSC 330 Lecture 24: Deployment and conclusion\n\n\n \n\n\n\n\n\n\nCPSC 330: Midterm 1 review\n\n\n \n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides-04.html#pod-work-discuss-these-questions",
    "href": "slides-04.html#pod-work-discuss-these-questions",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Pod Work: Discuss these questions",
    "text": "Pod Work: Discuss these questions\n\nWhy do we split data?\nWhat are train/valid/test splits?\nWhat are the benefits of cross-validation?\nWhat’s the fundamental trade-off in supervised machine learning?\nWhat is the golden rule of machine learning?"
  },
  {
    "objectID": "slides-04.html#recap-the-fundamental-tradeoff",
    "href": "slides-04.html#recap-the-fundamental-tradeoff",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Recap: The fundamental tradeoff",
    "text": "Recap: The fundamental tradeoff\nAs you increase the model complexity, training score tends to go up and the gap between train and validation scores tends to go up."
  },
  {
    "objectID": "slides-04.html#pod-work-discuss-this-question",
    "href": "slides-04.html#pod-work-discuss-this-question",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Pod Work: Discuss this question",
    "text": "Pod Work: Discuss this question\nWhich of the following statements about overfitting is true?\n\n\nOverfitting is always beneficial for model performance on unseen data.\n\n\nSome degree of overfitting is common in most real-world problems.\n\n\nOverfitting ensures the model will perform well in real-world scenarios.\n\n\nOverfitting occurs when the model learns the training data too closely, including its noise and outliers."
  },
  {
    "objectID": "slides-04.html#pod-work-discuss-this-question-1",
    "href": "slides-04.html#pod-work-discuss-this-question-1",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Pod Work: Discuss this question",
    "text": "Pod Work: Discuss this question\nWhich of the following scenarios do NOT necessarily imply overfitting?\n\n\nTraining accuracy is 0.98 while validation accuracy is 0.60.\n\n\nThe model is too specific to the training data.\n\n\nThe decision boundary of a classifier is wiggly and highly irregular.\n\n\nTraining and validation accuracies are both approximately 0.88."
  },
  {
    "objectID": "slides-04.html#pod-work-discuss-this-question-2",
    "href": "slides-04.html#pod-work-discuss-this-question-2",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Pod Work: Discuss this question",
    "text": "Pod Work: Discuss this question\nHow might one address the issue of underfitting in a machine learning model.\n\n\nIntroduce more noise to the training data.\n\n\nRemove features that might be relevant to the prediction.\n\n\nIncrease the model’s complexity, possibly by adding more parameter or features\n\n\nUse a smaller dataset for training.\n\n\nUse a larger dataset for training."
  },
  {
    "objectID": "slides-04.html#overfitting-and-underfitting",
    "href": "slides-04.html#overfitting-and-underfitting",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\n\nAn overfit model matches the training set so closely that it fails to make correct predictions on new unseen data.\n\nAn underfit model is too simple and does not even make good predictions on the training data"
  },
  {
    "objectID": "slides-04.html#overfitting-and-underfitting-1",
    "href": "slides-04.html#overfitting-and-underfitting-1",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\n\nSource"
  },
  {
    "objectID": "slides-04.html#iclicker-4.1",
    "href": "slides-04.html#iclicker-4.1",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "iClicker 4.1",
    "text": "iClicker 4.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nAnalogy-based models find examples from the test set that are most similar to the query example we are predicting.\n\n\nEuclidean distance will always have a non-negative value.\n\n\nWith \\(k\\)-NN, setting the hyperparameter \\(k\\) to larger values typically reduces training error.\n\n\nSimilar to decision trees, \\(k\\)-NNs finds a small set of good features.\n\n\nIn \\(k\\)-NN, with \\(k &gt; 1\\), the classification of the closest neighbour to the test example always contributes the most to the prediction."
  },
  {
    "objectID": "slides-04.html#iclicker-4.2",
    "href": "slides-04.html#iclicker-4.2",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "iClicker 4.2",
    "text": "iClicker 4.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\n\\(k\\)-NN may perform poorly in high-dimensional space (say, d &gt; 1000).\n\n\nIn sklearn’s SVC classifier, large values of gamma tend to result in higher training score but probably lower validation score.\n\n\nIf we increase both gamma and C, we can’t be certain if the model becomes more complex or less complex."
  },
  {
    "objectID": "slides-04.html#break",
    "href": "slides-04.html#break",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Break",
    "text": "Break\nLet’s take a break!"
  },
  {
    "objectID": "slides-04.html#similarity-based-algorithms",
    "href": "slides-04.html#similarity-based-algorithms",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Similarity-based algorithms",
    "text": "Similarity-based algorithms\n\nUse similarity or distance metrics to predict targets.\nExamples: \\(k\\)-nearest neighbors, Support Vector Machines (SVMs) with RBF Kernel."
  },
  {
    "objectID": "slides-04.html#k-nearest-neighbours",
    "href": "slides-04.html#k-nearest-neighbours",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "\\(k\\)-nearest neighbours",
    "text": "\\(k\\)-nearest neighbours\n\nClassifies an object based on the majority label among its \\(k\\) closest neighbors.\nMain hyperparameter: \\(k\\) or n_neighbors in sklearn\nDistance Metrics: Euclidean\nStrengths: simple and intuitive, can learn complex decision boundaries\nChallenges: Sensitive to the choice of distance metric and scaling (coming up)."
  },
  {
    "objectID": "slides-04.html#curse-of-dimensionality",
    "href": "slides-04.html#curse-of-dimensionality",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Curse of dimensionality",
    "text": "Curse of dimensionality\n\nAs dimensionality increases, the volume of the space increases exponentially, making the data sparse.\nDistance metrics lose meaning\n\nAccidental similarity swamps out meaningful similarity\nAll points become almost equidistant.\n\nOverfitting becomes likely: Harder to generalize with high-dimensional data.\nHow to deal with this?\n\nDimensionality reduction (PCA) (not covered in this course)\nFeature selection techniques."
  },
  {
    "objectID": "slides-04.html#svms-with-rbf-kernel",
    "href": "slides-04.html#svms-with-rbf-kernel",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "SVMs with RBF kernel",
    "text": "SVMs with RBF kernel\n\nRBF Kernel: Radial Basis Function, a way to transform data into higher dimensions implicitly.\nStrengths\n\nEffective in high-dimensional and sparse data\nGood performance on non-linear problems.\n\nHyperparameters:\n\n\\(C\\): Regularization parameter (trade-off between correct classification of training examples and maximization of the decision margin).\n\\(\\gamma\\) (Gamma): Defines how far the influence of a single training example reaches."
  },
  {
    "objectID": "slides-04.html#intuition-of-c-and-gamma-in-svm-rbf",
    "href": "slides-04.html#intuition-of-c-and-gamma-in-svm-rbf",
    "title": "Lecture 4: \\(k\\)-nearest neighbours and SVM RBFs",
    "section": "Intuition of C and gamma in SVM RBF",
    "text": "Intuition of C and gamma in SVM RBF\n\nC (Regularization): Controls the trade-off between perfect training accuracy and having a simpler decision boundary.\n\nHigh C: Strict, complex boundary (overfitting risk).\nLow C: More errors allowed, smoother boundary (generalizes better).\n\nGamma (Kernel Width): Controls the influence of individual data points.\n\nHigh Gamma: Points have local impact, complex boundary.\nLow Gamma: Points affect broader areas, smoother boundary.\n\nKey trade-off: Proper balance between C and gamma is crucial for avoiding overfitting or underfitting."
  },
  {
    "objectID": "slides-05.html#announcements",
    "href": "slides-05.html#announcements",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Announcements",
    "text": "Announcements"
  },
  {
    "objectID": "slides-05.html#recap",
    "href": "slides-05.html#recap",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Recap",
    "text": "Recap\n\nDecision trees: Split data into subsets based on feature values to create decision rules\n\\(k\\)-NNs: Classify based on the majority vote from k nearest neighbors\nSVM RBFs: Create a boundary using an RBF kernel to separate classes"
  },
  {
    "objectID": "slides-05.html#recap-1",
    "href": "slides-05.html#recap-1",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Recap",
    "text": "Recap\n\n\n\n\n\n\n\n\n\nAspect\nDecision Trees\nK-Nearest Neighbors (KNN)\nSupport Vector Machines (SVM) with RBF Kernel\n\n\n\n\nMain hyperparameters\nMax depth, min samples split\nNumber of neighbors (\\(k\\))\nC (regularization), Gamma (RBF kernel width)\n\n\nInterpretability\n\n\n\n\n\nHandling of Non-linearity\n\n\n\n\n\nScalability\n\n\n\n\n\n\n\nInterpretability (output easy to understand): - DT is very interpretable - KNN is moderately interpretable - SVM-RBF not interpretable at all\nNon-linearity: - DT Handle non-linearity, but boundaries are boxy - KNN can identify non-linear boundaries - SVM-RBF is a great choice for non-linearity\nScalability: - DT is very scalable, fast and can be done on large datasets - KNN is not scalable, because the distance needs to be calculated - SVM-RB is scalable, optimization is complicated so will be expensive"
  },
  {
    "objectID": "slides-05.html#recap-2",
    "href": "slides-05.html#recap-2",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Recap",
    "text": "Recap\n\n\n\n\n\n\n\n\n\nAspect\nDecision Trees\nK-Nearest Neighbors (KNN)\nSupport Vector Machines (SVM) with RBF Kernel\n\n\n\n\nSensitivity to Outliers\n\n\n\n\n\nMemory Usage\n\n\n\n\n\nTraining Time\n\n\n\n\n\nPrediction Time\n\n\n\n\n\nMulticlass support\n\n\n\n\n\n\n\nSensitivity to Outliers - DT has some sensitivity to outliers (based on where the splits happen) - KNN is distance based, not that sensitive to outliers, but depends on the number of neighbours - SVM-RBF robust to outliers\nMemory Usage - DT is is very memory efficient, stores the model not the data - KNN uses a lot of memory, all data sets stored in memory - SVM-RBF is reasonably memory efficient, stores only support vectors\nTraining Time - DT training time is higher than KNN - KNN is 0, all points are stored - SVM-RBF much lower compared to KNN and DT\nPrediction Time - DT, also very efficient at predicting - KNN is high, all the work happens here - SVM-RBF, very efficient at predicting\nMulticlass Support - DT, multi-class is fine - KNN, multi-class is fine - SVM-RBF, bit complicated"
  },
  {
    "objectID": "slides-05.html#iclicker-exercise-5.1",
    "href": "slides-05.html#iclicker-exercise-5.1",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "(iClicker) Exercise 5.1",
    "text": "(iClicker) Exercise 5.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nTake a guess: In your machine learning project, how much time will you typically spend on data preparation and transformation?\n\n\n~80% of the project time\n\n\n~20% of the project time\n\n\n~50% of the project time\n\n\nNone. Most of the time will be spent on model building\n\n\nThe question is adapted from here."
  },
  {
    "objectID": "slides-05.html#iclicker-exercise-5.2",
    "href": "slides-05.html#iclicker-exercise-5.2",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "(iClicker) Exercise 5.2",
    "text": "(iClicker) Exercise 5.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nStandardScaler ensures a fixed range (i.e., minimum and maximum values) for the features.\n\n\nStandardScaler calculates mean and standard deviation for each feature separately.\n\n\nIn general, it’s a good idea to apply scaling on numeric features before training \\(k\\)-NN or SVM RBF models.\n\n\nThe transformed feature values might be hard to interpret for humans.\n\n\nAfter applying SimpleImputer The transformed data has a different shape than the original data."
  },
  {
    "objectID": "slides-05.html#iclicker-exercise-5.3",
    "href": "slides-05.html#iclicker-exercise-5.3",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "(iClicker) Exercise 5.3",
    "text": "(iClicker) Exercise 5.3\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nYou can have scaling of numeric features, one-hot encoding of categorical features, and scikit-learn estimator within a single pipeline.\n\n\nOnce you have a scikit-learn pipeline object with an estimator as the last step, you can call fit, predict, and score on it.\n\n\nYou can carry out data splitting within scikit-learn pipeline.\n\n\nWe have to be careful of the order we put each transformation and model in a pipeline.\n\n\nIf you call cross_validate with a pipeline object, it will call fit and transform on the training fold and only transform on the validation fold.\n\n\n\nA: False; It doesn’t make sense to apply one hot encoding to numeric features, and it doesn’t make sense to apply standard scalar to categorical features. Sequence doesn’t make sense, we need column transformers\nB: True; can do this as long as the estimator is the last step\nC: False\nD: True;"
  },
  {
    "objectID": "slides-05.html#break",
    "href": "slides-05.html#break",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Break",
    "text": "Break\nLet’s take a break!\n /"
  },
  {
    "objectID": "slides-05.html#preprocessing-motivation-example",
    "href": "slides-05.html#preprocessing-motivation-example",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Preprocessing motivation: example",
    "text": "Preprocessing motivation: example\nYou’re trying to find a suitable date based on:\n\nAge (closer to yours is better).\nNumber of Facebook Friends (closer to your social circle is ideal)."
  },
  {
    "objectID": "slides-05.html#preprocessing-motivation-example-1",
    "href": "slides-05.html#preprocessing-motivation-example-1",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Preprocessing motivation: example",
    "text": "Preprocessing motivation: example\n\nYou are 30 years old and have 250 Facebook friends.\n\n\n\n\n\n\n\n\n\n\n\nPerson\nAge\n#FB Friends\nEuclidean Distance Calculation\nDistance\n\n\n\n\nA\n25\n400\n√(5² + 150²)\n150.08\n\n\nB\n27\n300\n√(3² + 50²)\n50.09\n\n\nC\n30\n500\n√(0² + 250²)\n250.00\n\n\nD\n60\n250\n√(30² + 0²)\n30.00\n\n\n\nBased on the distances, the two nearest neighbors (2-NN) are:\n\nPerson D (Distance: 30.00)\nPerson B (Distance: 50.09)\n\nWhat’s the problem here?"
  },
  {
    "objectID": "slides-05.html#imputation-fill-the-gaps",
    "href": "slides-05.html#imputation-fill-the-gaps",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Imputation: Fill the gaps! (🟩 🟧 🟦)",
    "text": "Imputation: Fill the gaps! (🟩 🟧 🟦)\nFill in missing data using a chosen strategy:\n\nMean: Replace missing values with the average of the available data.\nMedian: Use the middle value.\nMost Frequent: Use the most common value (mode).\nKNN Imputation: Fill based on similar neighbors.\n\nExample:\nFill in missing values like filling empty seats in a classroom with the average student.\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\nX_imputed = imputer.fit_transform(X)"
  },
  {
    "objectID": "slides-05.html#scaling-everything-to-the-same-range",
    "href": "slides-05.html#scaling-everything-to-the-same-range",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Scaling: Everything to the same range! (📉 📈)",
    "text": "Scaling: Everything to the same range! (📉 📈)\nEnsure all features have a comparable range.\n\nStandardScaler: Mean = 0, Standard Deviation = 1.\nMinMaxScaler: Scales features to a [0, 1] range.\nRobustScaler: Scales features using median and quantiles.\n\nExample:\nRescaling everyone’s height to make basketball players and gymnasts comparable.\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)"
  },
  {
    "objectID": "slides-05.html#one-hot-encoding-1-0-0",
    "href": "slides-05.html#one-hot-encoding-1-0-0",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "One-Hot encoding: 🍎 → 1️⃣ 0️⃣ 0️⃣",
    "text": "One-Hot encoding: 🍎 → 1️⃣ 0️⃣ 0️⃣\nConvert categorical features into binary columns.\n\nCreates new binary columns for each category.\nUseful for handling categorical data in machine learning models.\n\nExample:\nTurn “Apple, Banana, Orange” into binary columns:\n\n\n\nFruit\n🍎\n🍌\n🍊\n\n\n\n\nApple 🍎\n1\n0\n0\n\n\nBanana 🍌\n0\n1\n0\n\n\nOrange 🍊\n0\n0\n1\n\n\n\nfrom sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nX_encoded = encoder.fit_transform(X)"
  },
  {
    "objectID": "slides-05.html#ordinal-encoding-ranking-matters-1",
    "href": "slides-05.html#ordinal-encoding-ranking-matters-1",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Ordinal encoding: Ranking matters! (⭐️⭐️⭐️⭐️⭐️ → 1️⃣)",
    "text": "Ordinal encoding: Ranking matters! (⭐️⭐️⭐️⭐️⭐️ → 1️⃣)\nConvert categories into integer values that have a meaningful order.\n\nAssign integers based on order or rank.\nUseful when there is an inherent ranking in the data.\n\nExample:\nTurn “Poor, Average, Good” into 1, 2, 3:\n\n\n\nRating\nOrdinal\n\n\n\n\nPoor\n1\n\n\nAverage\n2\n\n\nGood\n3\n\n\n\nfrom sklearn.preprocessing import OrdinalEncoder\nencoder = OrdinalEncoder()\nX_ordinal = encoder.fit_transform(X)"
  },
  {
    "objectID": "slides-05.html#transformers",
    "href": "slides-05.html#transformers",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Transformers",
    "text": "Transformers\n\nAre used to transform or preprocess data.\nImplement the fit and transform methods.\n\nfit(X): Learns parameters from the data.\ntransform(X): Applies the learned transformation to the data.\n\nExamples:\n\nImputation (SimpleImputer): Fills missing values.\nScaling (StandardScaler): Standardizes features."
  },
  {
    "objectID": "slides-05.html#estimators",
    "href": "slides-05.html#estimators",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "Estimators",
    "text": "Estimators\n\nUsed to make predictions.\nImplement fit and predict methods.\n\nfit(X, y): Learns from labeled data.\npredict(X): Makes predictions on new data.\n\nExamples: DecisionTreeClassifier, SVC, KNeighborsClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\ntree_clf = DecisionTreeClassifier()"
  },
  {
    "objectID": "slides-05.html#the-golden-rule-in-feature-transformations",
    "href": "slides-05.html#the-golden-rule-in-feature-transformations",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "The golden rule in feature transformations",
    "text": "The golden rule in feature transformations\n\nNever transform the entire dataset at once!\nWhy? It leads to data leakage — using information from the test set in your training process, which can artificially inflate model performance.\nFit transformers like scalers and imputers on the training set only.\nApply the transformations to both the training and test sets separately.\n\nExample:\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)"
  },
  {
    "objectID": "slides-05.html#sklearn-pipelines",
    "href": "slides-05.html#sklearn-pipelines",
    "title": "Lecture 5: Preprocessing and sklearn pipelines",
    "section": "sklearn Pipelines",
    "text": "sklearn Pipelines\n\nPipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\nSimplify the code and improves readability.\nReduce the risk of data leakage by ensuring proper transformation of the training and test sets.\nAutomatically apply transformations in sequence.\n\nExample:\nChaining a StandardScaler with a KNeighborsClassifier model.\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\n\npipeline = make_pipeline(StandardScaler(), KNeighborsClassifier())\n\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to CPSC330! Here, you’ll find slides for CPSC 330. These slides are based on the notes present here.\n\nClass times 🕘 10 AM to 1 PM, Monday, Wednesday, Friday\nWhere? 📍 Hugh Dempster Pavillion 310, 6245 Agronomy Road, Vancouver, BC V6T 1Z4"
  },
  {
    "objectID": "slides-14.html#finishing-up-feature-selection",
    "href": "slides-14.html#finishing-up-feature-selection",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Finishing up Feature Selection",
    "text": "Finishing up Feature Selection\nLast class we distinguished between Model-based selection and recursive feature feature elimination (RFE).\nLet’s chat a bit more about Recursive Feature Elimination with Cross-validation."
  },
  {
    "objectID": "slides-14.html#pause-and-reflect",
    "href": "slides-14.html#pause-and-reflect",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Pause and Reflect",
    "text": "Pause and Reflect\nWe are now just over half-way through CPSC 330!\nYou had a midterm already a couple of weeks ago, I’d like some feedback on how things are going in class (as the instructor)."
  },
  {
    "objectID": "slides-14.html#class-survey",
    "href": "slides-14.html#class-survey",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Class Survey",
    "text": "Class Survey\nI’d love to hear how you think lectures are going, and how the course is going overall: bit.ly/cpsc330_24W1."
  },
  {
    "objectID": "slides-14.html#iclicker-midterm-poll",
    "href": "slides-14.html#iclicker-midterm-poll",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "(iClicker) Midterm poll",
    "text": "(iClicker) Midterm poll\nSelect all of the following statements which are TRUE.\n\n\nI’m happy with my progress and learning in this course.\n\n\nI find the course content interesting, but the pace is a bit overwhelming. Balancing this course with other responsibilities is challenging\n\n\nI’m doing okay, but I feel stressed and worried about upcoming assessments.\n\n\nI’m confused about some concepts and would appreciate more clarification or review sessions.\n\n\nI’m struggling to keep up with the material. I am not happy with my learning in this course and my morale is low ☹️."
  },
  {
    "objectID": "slides-14.html#supervised-learning",
    "href": "slides-14.html#supervised-learning",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Supervised learning",
    "text": "Supervised learning\n\nTraining data comprises a set of observations (X) and their corresponding targets (y).\nWe wish to find a model function f that relates X to y.\nThen use that model function to predict the targets of new examples.\nWe have been working with this set up so far."
  },
  {
    "objectID": "slides-14.html#unsupervised-learning",
    "href": "slides-14.html#unsupervised-learning",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Unsupervised learning",
    "text": "Unsupervised learning\n\nTraining data consists of observations (X) without any corresponding targets.\nUnsupervised learning could be used to group similar things together in X or to find underlying structure in the data."
  },
  {
    "objectID": "slides-14.html#clustering-activity",
    "href": "slides-14.html#clustering-activity",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "Clustering Activity",
    "text": "Clustering Activity\n\n\nCategorize the food items in the image and write your categories. Do you think there is one correct way to cluster these images? Why or why not?\nIf you want to build a machine learning model to cluster such images how would you represent such images?"
  },
  {
    "objectID": "slides-14.html#the-perfect-spaghetti-sauce",
    "href": "slides-14.html#the-perfect-spaghetti-sauce",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The “perfect” spaghetti sauce",
    "text": "The “perfect” spaghetti sauce\nSuppose you are a hypothetical spaghetti sauce company and you’re asked to create the “perfect” spaghetti sauce which makes all your customers happy. The truth is humans are diverse and there is no “perfect” spaghetti sauce. There are “perfect” spaghetti sauces that cater to different tastes!"
  },
  {
    "objectID": "slides-14.html#the-perfect-spaghetti-sauce-1",
    "href": "slides-14.html#the-perfect-spaghetti-sauce-1",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The “perfect” spaghetti sauce",
    "text": "The “perfect” spaghetti sauce\nHoward Moskowitz found out that Americans fall into one of the following three categories:\n\npeople who like their spaghetti sauce plain\npeople who like their spaghetti sauce spicy\npeople who like their spaghetti sauce extra chunky\n\n Reference: Malcolm Gladwell’s Ted talk"
  },
  {
    "objectID": "slides-14.html#the-perfect-spaghetti-sauce-2",
    "href": "slides-14.html#the-perfect-spaghetti-sauce-2",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The “perfect” spaghetti sauce",
    "text": "The “perfect” spaghetti sauce\n\nIf one “perfect” authentic sauce satisfies 60%, of the people on average, creating several tailored sauce clusters could increase average happiness to between 75% to 78%.\nCan we apply this concept of clustering and tailoring solutions to specific groups in machine learning?"
  },
  {
    "objectID": "slides-14.html#k-means-clustering",
    "href": "slides-14.html#k-means-clustering",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "K-means Clustering",
    "text": "K-means Clustering\n\nAlgorithm Steps:\n\nSelect K initial centroids.\nAssign each data point to the nearest centroid.\nRecalculate centroids based on assigned points.\nRepeat until centroids stabilize or reach a maximum number of iterations."
  },
  {
    "objectID": "slides-14.html#k-means-example",
    "href": "slides-14.html#k-means-example",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "K-Means example",
    "text": "K-Means example"
  },
  {
    "objectID": "slides-14.html#k-means-pros-and-cons",
    "href": "slides-14.html#k-means-pros-and-cons",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "K-Means pros and cons",
    "text": "K-Means pros and cons\n\nAdvantages:\n\nSimple and efficient for large datasets.\nWorks well with spherical clusters.\n\nLimitations:\n\nNeeds pre-defined K.\nSensitive to outliers and initial centroid placement."
  },
  {
    "objectID": "slides-14.html#iclicker-exercise-15.1",
    "href": "slides-14.html#iclicker-exercise-15.1",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "iClicker Exercise 15.1",
    "text": "iClicker Exercise 15.1\nSelect all of the following statements which are True\n\n\nK-Means algorithm always converges to the same solution.\n\n\nK in K-Means should always be ≤ # of features.\n\n\nIn K-Means, it makes sense to have K ≤ # of examples.\n\n\nIn K-Means, in some iterations some points may be left unassigned."
  },
  {
    "objectID": "slides-14.html#iclicker-exercise-15.2",
    "href": "slides-14.html#iclicker-exercise-15.2",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "iClicker Exercise 15.2",
    "text": "iClicker Exercise 15.2\nSelect all of the following statements which are True\n\n\nK-Means is sensitive to initialization and the solution may change depending upon the initialization.\n\n\nK-means terminates when the number of clusters does not increase between iterations.\n\n\nK-means terminates when the centroid locations do not change between iterations.\n\n\nK-Means is guaranteed to find the optimal solution."
  },
  {
    "objectID": "slides-14.html#the-elbow-method",
    "href": "slides-14.html#the-elbow-method",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The Elbow Method",
    "text": "The Elbow Method\n\nPurpose: Identify the optimal number of clusters (K).\nHow it Works:\n\nPlot intra-cluster distances for different values of K.\nLook for the “elbow” point where the intra-cluster reduction slows.\n\nInterpretation:\n\nThe point of diminishing returns suggests a good K."
  },
  {
    "objectID": "slides-14.html#the-elbow-method-example",
    "href": "slides-14.html#the-elbow-method-example",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The Elbow method example",
    "text": "The Elbow method example"
  },
  {
    "objectID": "slides-14.html#the-silhouette-method",
    "href": "slides-14.html#the-silhouette-method",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The Silhouette method",
    "text": "The Silhouette method\n\nSilhouette Score: Measures how well data points fit within their cluster.\n\n$s(i) = \\frac{b(i) - a(i)}{\\max (a(i), b(i))}$\n\na(i): Mean distance to other points in the same cluster.\nb(i): Mean distance to points in the nearest neighboring cluster."
  },
  {
    "objectID": "slides-14.html#the-silhouette-method-1",
    "href": "slides-14.html#the-silhouette-method-1",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "The Silhouette method",
    "text": "The Silhouette method\n\nRange: -1 to 1\n\n1: Perfect clustering.\n0: Overlapping clusters.\nNegative: Poor clustering.\n\nHigher average silhouette score indicates “better” clustering."
  },
  {
    "objectID": "slides-14.html#iclicker-exercise-15.3",
    "href": "slides-14.html#iclicker-exercise-15.3",
    "title": "CPSC 330 Lecture 14: K-Means",
    "section": "iClicker Exercise 15.3",
    "text": "iClicker Exercise 15.3\nSelect all of the following statements which are True\n\n\nIf you train K-Means with n_clusters= the number of examples, the inertia value will be 0.\n\n\nThe elbow plot shows the tradeoff between within cluster distance and the number of clusters.\n\n\nUnlike the Elbow method, the Silhouette method is not dependent on the notion of cluster centers.\n\n\nThe elbow plot is not a reliable method to obtain the optimal number of clusters in all cases.\n\n\nThe Silhouette scores ranges between -1 and 1 where higher scores indicates better cluster assignments.\n\n\n\ns"
  },
  {
    "objectID": "slides-08.html#recap-logistic-regression",
    "href": "slides-08.html#recap-logistic-regression",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Recap: Logistic regression",
    "text": "Recap: Logistic regression\n\nA linear model used for binary classification tasks.\n\nThere is a variant of logistic regression called multinomial logistic regression for multiclass classification.\n\nParameters:\n\nCoefficients (Weights): The model learns a coefficient or a weight associated with each feature that represents its importance.\nBias (Intercept): A constant term added to the linear combination of features and their coefficients."
  },
  {
    "objectID": "slides-08.html#recap-logistic-regression-1",
    "href": "slides-08.html#recap-logistic-regression-1",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Recap: Logistic regression",
    "text": "Recap: Logistic regression\n\nThe model computes a weighted sum of the input features’ values, adjusted by their respective coefficients and the bias term.\nThis weighted sum is passed through a sigmoid function to transform it into a probability score, indicating the likelihood of the input belonging to the “positive” class.\n\n\\[\\begin{equation}\nP_{hat} = \\sigma\\left(\\sum_{i=1}^d w_i x_i + b\\right)\n\\end{equation}\\]\n\n\\(P_{hat}\\) is the predicted probability of the example belonging to the positive class.\n\\(w_i\\) is the learned weight associated with feature \\(i\\)\n\\(x_i\\) is the value of the input feature \\(i\\)\n\\(b\\) is the bias term"
  },
  {
    "objectID": "slides-08.html#recap-logistic-regression-2",
    "href": "slides-08.html#recap-logistic-regression-2",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Recap: Logistic regression",
    "text": "Recap: Logistic regression\n\nFor a dataset with \\(d\\) features, the decision boundary that separates the classes is a \\(d-1\\) dimensional hyperplane.\n\nComplexity hyperparameter: C in sklearn.\n\nHigher C \\(\\rightarrow\\) more complex model meaning larger coefficients\nLower C \\(\\rightarrow\\) less complex model meaning smaller coefficients"
  },
  {
    "objectID": "slides-08.html#recap-countvectorizer-input",
    "href": "slides-08.html#recap-countvectorizer-input",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Recap: CountVectorizer input",
    "text": "Recap: CountVectorizer input\n\nPrimarily designed to accept either a pandas.Series of text data or a 1D numpy array. It can also process a list of string data directly.\nUnlike many transformers that handle multiple features (DataFrame or 2D numpy array), CountVectorizer a single text column at a time.\nIf your dataset contains multiple text columns, you will need to instantiate separate CountVectorizer objects for each text feature.\nThis approach ensures that the unique vocabulary and tokenization processes are correctly applied to each specific text column without interference."
  },
  {
    "objectID": "slides-08.html#hyperparameter-optimization-motivation",
    "href": "slides-08.html#hyperparameter-optimization-motivation",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Hyperparameter optimization motivation",
    "text": "Hyperparameter optimization motivation"
  },
  {
    "objectID": "slides-08.html#data",
    "href": "slides-08.html#data",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Data",
    "text": "Data\n\nsms_df = pd.read_csv(DATA_DIR + \"spam.csv\", encoding=\"latin-1\")\nsms_df = sms_df.drop(columns = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])\nsms_df = sms_df.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"})\ntrain_df, test_df = train_test_split(sms_df, test_size=0.10, random_state=42)\nX_train, y_train = train_df[\"sms\"], train_df[\"target\"]\nX_test, y_test = test_df[\"sms\"], test_df[\"target\"]\ntrain_df.head(4)\n\n\n\n\n\n\n\n\ntarget\nsms\n\n\n\n\n3130\nspam\nLookAtMe!: Thanks for your purchase of a video...\n\n\n106\nham\nAight, I'll hit you up when I get some cash\n\n\n4697\nham\nDon no da:)whats you plan?\n\n\n856\nham\nGoing to take your babe out ?"
  },
  {
    "objectID": "slides-08.html#model-building",
    "href": "slides-08.html#model-building",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Model building",
    "text": "Model building\n\nLet’s define a pipeline\n\n\npipe_svm = make_pipeline(CountVectorizer(), SVC())\n\n\nSuppose we want to try out different hyperparameter values.\n\n\nparameters = {\n    \"max_features\": [100, 200, 400],\n    \"gamma\": [0.01, 0.1, 1.0],\n    \"C\": [0.01, 0.1, 1.0],\n}"
  },
  {
    "objectID": "slides-08.html#hyperparameter-optimization-with-loops",
    "href": "slides-08.html#hyperparameter-optimization-with-loops",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Hyperparameter optimization with loops",
    "text": "Hyperparameter optimization with loops\n\nDefine a parameter space.\nIterate through possible combinations.\nEvaluate model performance.\nWhat are some limitations of this approach?"
  },
  {
    "objectID": "slides-08.html#sklearn-methods",
    "href": "slides-08.html#sklearn-methods",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "sklearn methods",
    "text": "sklearn methods\n\nsklearn provides two main methods for hyperparameter optimization\n\nGrid Search\nRandom Search"
  },
  {
    "objectID": "slides-08.html#grid-search",
    "href": "slides-08.html#grid-search",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Grid Search",
    "text": "Grid Search\n\nCovers all possible combinations from the provided grid.\nCan be parallelized easily.\nIntegrates cross-validation."
  },
  {
    "objectID": "slides-08.html#grid-search-example",
    "href": "slides-08.html#grid-search-example",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Grid search example",
    "text": "Grid search example\n\nfrom sklearn.model_selection import GridSearchCV\n\npipe_svm = make_pipeline(CountVectorizer(), SVC())\n\nparam_grid = {\n    \"countvectorizer__max_features\": [100, 200, 400],\n    \"svc__gamma\": [0.01, 0.1, 1.0],\n    \"svc__C\": [0.01, 0.1, 1.0],\n}\ngrid_search = GridSearchCV(pipe_svm, \n                  param_grid = param_grid, \n                  n_jobs=-1, \n                  return_train_score=True\n                 )\ngrid_search.fit(X_train, y_train)\ngrid_search.best_score_\n\nnp.float64(0.9780612255051213)"
  },
  {
    "objectID": "slides-08.html#random-search",
    "href": "slides-08.html#random-search",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Random Search",
    "text": "Random Search\n\nMore efficient than grid search when dealing with large hyperparameter spaces.\nSamples a given number of parameter settings from distributions."
  },
  {
    "objectID": "slides-08.html#random-search-example",
    "href": "slides-08.html#random-search-example",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Random search example",
    "text": "Random search example\n\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\npipe_svc = make_pipeline(CountVectorizer(), SVC())\n\nparam_dist = {\n    \"countvectorizer__max_features\": randint(100, 2000), \n    \"svc__C\": uniform(0.1, 1e4),  # loguniform(1e-3, 1e3),\n    \"svc__gamma\": loguniform(1e-5, 1e3),\n}\nrandom_search = RandomizedSearchCV(pipe_svm,                                    \n                  param_distributions = param_dist, \n                  n_iter=10, \n                  n_jobs=-1, \n                  return_train_score=True)\n\n# Carry out the search\nrandom_search.fit(X_train, y_train)\nrandom_search.best_score_\n\nnp.float64(0.9794570380674343)"
  },
  {
    "objectID": "slides-08.html#optimization-bias",
    "href": "slides-08.html#optimization-bias",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Optimization bias",
    "text": "Optimization bias\n\nWhy do we need separate validation and test datasets?"
  },
  {
    "objectID": "slides-08.html#mitigating-optimization-bias.",
    "href": "slides-08.html#mitigating-optimization-bias.",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Mitigating optimization bias.",
    "text": "Mitigating optimization bias.\n\nCross-validation\nEnsembles\nRegularization and choosing a simpler model"
  },
  {
    "objectID": "slides-08.html#iclicker-exercise-8.1",
    "href": "slides-08.html#iclicker-exercise-8.1",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "(iClicker) Exercise 8.1",
    "text": "(iClicker) Exercise 8.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIf you get best results at the edges of your parameter grid, it might be a good idea to adjust the range of values in your parameter grid.\n\n\nGrid search is guaranteed to find the best hyperparameter values.\n\n\nIt is possible to get different hyperparameters in different runs of RandomizedSearchCV."
  },
  {
    "objectID": "slides-08.html#questions-for-you",
    "href": "slides-08.html#questions-for-you",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Questions for you",
    "text": "Questions for you\n\nYou have a dataset and you give me 1/10th of it. The dataset given to me is rather small and so I split it into 96% train and 4% validation split. I carry out hyperparameter optimization using a single 4% validation split and report validation accuracy of 0.97. Would it classify the rest of the data with similar accuracy?\n\nProbably\nProbably not"
  },
  {
    "objectID": "slides-08.html#questions-for-class-discussion",
    "href": "slides-08.html#questions-for-class-discussion",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Questions for class discussion",
    "text": "Questions for class discussion\n\nSuppose you have 10 hyperparameters, each with 4 possible values. If you run GridSearchCV with this parameter grid, how many experiments will be carried out?\nSuppose you have 10 hyperparameters and each takes 4 values. If you run RandomizedSearchCV with this parameter grid with n_iter=20, how many cross-validation experiments will be carried out?"
  },
  {
    "objectID": "slides-08.html#group-work-class-demo-live-coding",
    "href": "slides-08.html#group-work-class-demo-live-coding",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-08.html#group-work-invention-activity",
    "href": "slides-08.html#group-work-invention-activity",
    "title": "CPSC 330 Lecture 8: Hyperparameter Optimization",
    "section": "Group Work: Invention Activity",
    "text": "Group Work: Invention Activity\nSo far we have looked only at score as a metric for evaluating our metrics.\nWhat else could be used as a possible metric? Think of what else might be important for machine learning practioners and stakeholders?\nIn your group, brainstorm 4 alternative options:"
  },
  {
    "objectID": "slides-24.html#announcements",
    "href": "slides-24.html#announcements",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "Announcements",
    "text": "Announcements\n\nLast lecture today 🎉 !\nHW9 is due today Dec 5th at 11:59 PM (No late submission allowed.)\nEthics bonus assignment is due tomorrow at 11:59pm."
  },
  {
    "objectID": "slides-24.html#questions-for-you",
    "href": "slides-24.html#questions-for-you",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "❓❓ Questions for you",
    "text": "❓❓ Questions for you\nImagine you’ve created a machine learning model and are eager to share it with others. Consider the following scenarios for sharing your model:\n\nTo a non-technical Audience: How would you present your model to friends and family who may not have a technical background?\nTo a technical audience: How would you share your model with peers or professionals in the field who have a technical understanding of machine learning?\nIn an academic or research setting: How would you disseminate your model within academic or research communities?"
  },
  {
    "objectID": "slides-24.html#try-out-this-moment-predictor",
    "href": "slides-24.html#try-out-this-moment-predictor",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "Try out this moment predictor",
    "text": "Try out this moment predictor\nhttps://cpsc330-moment-predictor.onrender.com/\n\nIn this lecture, I will show you how to set up/develop this."
  },
  {
    "objectID": "slides-24.html#what-is-deployment",
    "href": "slides-24.html#what-is-deployment",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "What is deployment?",
    "text": "What is deployment?\n\nAfter we train a model, we want to use it!\nThe user likely does not want to install your Python stack, train your model.\nYou don’t necessarily want to share their dataset.\nSo we need to do two things:\n\nSave/store your model for later use.\nMake the saved model conveniently accessible."
  },
  {
    "objectID": "slides-24.html#we-will-use-the-tools-below-for",
    "href": "slides-24.html#we-will-use-the-tools-below-for",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "We will use the tools below for",
    "text": "We will use the tools below for\n\nSaving the model: We will use Joblib\nMaking the saved model conveniently accessible: Flask & render"
  },
  {
    "objectID": "slides-24.html#web-app",
    "href": "slides-24.html#web-app",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "Web App",
    "text": "Web App"
  },
  {
    "objectID": "slides-24.html#api",
    "href": "slides-24.html#api",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "API",
    "text": "API"
  },
  {
    "objectID": "slides-24.html#course-evaluations-10-mins",
    "href": "slides-24.html#course-evaluations-10-mins",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "Course evaluations (~10 mins)",
    "text": "Course evaluations (~10 mins)\nhttps://canvas.ubc.ca/courses/149122/external_tools/53187\n\nThey help us improve our teaching!\nUBC & CS uses them to provide rewards to instructors and TAs who are doing well!\nUBC & CS uses them to identify where instructors, TAs and courses need additional supports to improve.\nUBC uses these in evaluating professors for tenure and promotion.\nI’ll very much appreciate your constructive and concrete feedback."
  },
  {
    "objectID": "slides-24.html#what-did-we-cover",
    "href": "slides-24.html#what-did-we-cover",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "What did we cover",
    "text": "What did we cover\n\nPart 1: Supervised learning on tabular data: ML fundamentals, preprocessing and data encoding, a bunch of models, evaluation metrics, feature importances and model transparency, feature selection, hyperparameter optimization\nPart 2: Dealing with other non-tabular data types: Clustering, recommender systems, computer vision with pre-trained deep learning models (high level), language data, text preprocessing, embeddings, topic modeling, time series, right-censored data / survival analysis\nPart 3: Communication, Ethics, and Deployment"
  },
  {
    "objectID": "slides-24.html#what-we-didnt-cover",
    "href": "slides-24.html#what-we-didnt-cover",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "What we didn’t cover",
    "text": "What we didn’t cover\n\nHow do these models work under the hood"
  },
  {
    "objectID": "slides-24.html#what-would-i-do-differently",
    "href": "slides-24.html#what-would-i-do-differently",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "What would I do differently?",
    "text": "What would I do differently?\nLots of room for improvement. Here are some things on my mind.\n\nBalance the pace of the course a bit more (too intense at the beginning, too relaxed at the end!)\nFlipped classroom in a more effective way in the first part of the course.\nMore demos during lecture time\nWorksheets/practice questions during tutorials\nAdd a course project !?!\nAdd more interactive components in the lectures\nSome material to cover: dealing with outliers, data collection, large language models"
  },
  {
    "objectID": "slides-24.html#what-next",
    "href": "slides-24.html#what-next",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "What next?",
    "text": "What next?\nIf you want to further develop your machine learning skills: - Practice! - Work on your own projects - Work hard and be consistent.\n\nIf you are interested in research in machine learning\n\nTake CPSC 340. If you do not have the required prereqs you can try to audit it.\n\nGet into the habit of reading papers and replicating results"
  },
  {
    "objectID": "slides-24.html#questions-for-you-1",
    "href": "slides-24.html#questions-for-you-1",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "❓❓ Questions for you",
    "text": "❓❓ Questions for you\nFor each of the scenarios below\n\nIdentify if ML is a good solution for a problem.\nIf yes\n\nFrame the problem to a ML problem.\nDiscuss what kind of features you would need to effectively solve the problem\nWhat would be a reasonable baseline?\nWhich model would be a suitable model for the given scenario?\nWhat would be the appropriate success metrics."
  },
  {
    "objectID": "slides-24.html#questions-for-you-2",
    "href": "slides-24.html#questions-for-you-2",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "❓❓ Questions for you",
    "text": "❓❓ Questions for you\n\n\n\n\n\n\n\nApp\nGoal\n\n\n\n\nQueuePredictor app\nInform callers how long they’ll wait on hold given the current call volume\n\n\nTo-doList App\nKeep track of the tasks that a user inputs and organize them by date\n\n\nSegmentSphere App\nTo segment customers to tailor marketing strategies based on purchasing behavior\n\n\nVideo app\nRecommend useful videos\n\n\nDining app\nIdentify cuisine by a restaurant’s menu\n\n\nWeather app\nCalculate precipitation in six hour increments for a geographic region\n\n\nEvoCarShare app\nCalculate number of car rentals in four increaments at a particular Evo parking spot\n\n\nPharma app\nUnderstand the effect of a new drug on patient survival time"
  },
  {
    "objectID": "slides-24.html#conclusion-farewell",
    "href": "slides-24.html#conclusion-farewell",
    "title": "CPSC 330 Lecture 24: Deployment and conclusion",
    "section": "Conclusion & farewell",
    "text": "Conclusion & farewell\nThat’s all, folks. We made it! Good luck on your final exam! When you get a chance, please let me know what worked for you and what didn’t work for you in this course."
  },
  {
    "objectID": "slides-17.html#recap-recommender-systems",
    "href": "slides-17.html#recap-recommender-systems",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Recap: Recommender Systems",
    "text": "Recap: Recommender Systems\nHow the heck did I split the data last class!?"
  },
  {
    "objectID": "slides-17.html#beyond-error-rate-in-recommender-systems",
    "href": "slides-17.html#beyond-error-rate-in-recommender-systems",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Beyond Error Rate in Recommender Systems",
    "text": "Beyond Error Rate in Recommender Systems\n\nIf a system gives the best RMSE it doesn’t necessarily mean that it’s going to give best recommendations.\nIn recommendation systems we do not have ground truth in the sense that there is no notion of “perfect” recommendations.\nTraining your model and evaluating it offline is not ideal."
  },
  {
    "objectID": "slides-17.html#beyond-error-rate-in-recommender-systems-1",
    "href": "slides-17.html#beyond-error-rate-in-recommender-systems-1",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Beyond Error Rate in Recommender Systems",
    "text": "Beyond Error Rate in Recommender Systems\n\nOther aspects such as simplicity, interpretation, code maintainability are equally (if not more) important than best validation error.\nWinning system of Netflix Challenge was never adopted.\n\nBig mess of ensembles was not really maintainable\n\nThere are also other considerations:\n\ndiversity\nfreshness\ntrust\npersistence"
  },
  {
    "objectID": "slides-17.html#iclicker-exercise-17.2",
    "href": "slides-17.html#iclicker-exercise-17.2",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "iClicker Exercise 17.2",
    "text": "iClicker Exercise 17.2\nSelect all of the following statements which are True (iClicker)\n\n\nIn content-based filtering we leverage available item features in addition to similarity between users.\n\n\nIn content-based filtering you represent each user in terms of known features of items.\n\n\nIn the set up of content-based filtering we discussed, if you have a new movie, you would have problems predicting ratings for that movie.\n\n\nIn content-based filtering if a user has a number of ratings in the training utility matrix but does not have any ratings in the validation utility matrix then we won’t be able to calculate RMSE for the validation utility matrix."
  },
  {
    "objectID": "slides-17.html#motivation-and-context",
    "href": "slides-17.html#motivation-and-context",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Motivation and Context",
    "text": "Motivation and Context\n\nDo large language models, such as ChatGPT, “understand” your questions to some extent and provide useful responses?\nWhat is required for a machine to “understand” language?\nSo far we have been talking about sentence or document representations.\nToday, we’ll go one step back and talk about word representations."
  },
  {
    "objectID": "slides-17.html#referential-ambiguity",
    "href": "slides-17.html#referential-ambiguity",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Referential Ambiguity",
    "text": "Referential Ambiguity\nLet’s start with this picture:\n\n\nHow do we know what the it is referring to?\nHow do we tell an algorithm that?"
  },
  {
    "objectID": "slides-17.html#activity-context-and-word-meaning",
    "href": "slides-17.html#activity-context-and-word-meaning",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Activity: Context and word meaning",
    "text": "Activity: Context and word meaning\nPair up with the person next to you and try to guess the meanings of two made-up words: flibbertigibbet and groak.\n\nAttribution: Thanks to ChatGPT 4o on Wed Nov. 6, 2024!"
  },
  {
    "objectID": "slides-17.html#demo",
    "href": "slides-17.html#demo",
    "title": "CPSC 330 Lecture 17: Natural Language Processing",
    "section": "Demo",
    "text": "Demo\nYou can follow along here!"
  },
  {
    "objectID": "slides-16.html#rest-of-cpsc-330",
    "href": "slides-16.html#rest-of-cpsc-330",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "Rest of CPSC 330",
    "text": "Rest of CPSC 330\nWe started CPSC 330 with Machine Learning fundamentals, Supervised Learning models, Unsupervised Learning models, more complex fundamentals like feature engineering and feature selection\nWe are now ready to try and solve different types of problems! - Today: Recommender Systems - Next class: Text Data and Topic Modelling - After: Images and Computer vision, Time Series Data, etc…"
  },
  {
    "objectID": "slides-16.html#iclicker-16.0",
    "href": "slides-16.html#iclicker-16.0",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "iClicker 16.0",
    "text": "iClicker 16.0\nWhat percentage of the total watch time on YouTube do you think comes from reccomendations?\n\n\n20%\n\n\n50%\n\n\n70%\n\n\n95%\n\n\nSource: MIT Technology Review"
  },
  {
    "objectID": "slides-16.html#what-is-a-recommender-system",
    "href": "slides-16.html#what-is-a-recommender-system",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "What is a Recommender System?",
    "text": "What is a Recommender System?\nA recommender or a recommendation system recommends a particular product or service to users they are likely to consume."
  },
  {
    "objectID": "slides-16.html#examples-of-recommender-systems",
    "href": "slides-16.html#examples-of-recommender-systems",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "Examples of Recommender Systems",
    "text": "Examples of Recommender Systems\n\nAmazon\nNetflix\nTinder\nFacebook\netc…\n\nWhat should be shown to the user so they buy more products/spend more time on the app/etc…"
  },
  {
    "objectID": "slides-16.html#ethics-of-recommender-systems",
    "href": "slides-16.html#ethics-of-recommender-systems",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "Ethics of Recommender Systems",
    "text": "Ethics of Recommender Systems\nWe should be very mindful of the drawbacks of relying on recommender systems.\nWhat are some ethical considersations of recommender systems?"
  },
  {
    "objectID": "slides-16.html#what-comprises-a-recommender-system",
    "href": "slides-16.html#what-comprises-a-recommender-system",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "What comprises a recommender system?",
    "text": "What comprises a recommender system?\nWhat does the problem formulation look like?\nWhat tools would/should we use to create a recommender system?"
  },
  {
    "objectID": "slides-16.html#notebook-for-lecture-17",
    "href": "slides-16.html#notebook-for-lecture-17",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "Notebook for Lecture 17",
    "text": "Notebook for Lecture 17\nYou can follow along here!"
  },
  {
    "objectID": "slides-16.html#break",
    "href": "slides-16.html#break",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "Break",
    "text": "Break\nLet’s take a 10 min break"
  },
  {
    "objectID": "slides-16.html#iclicker-exercise-16.1",
    "href": "slides-16.html#iclicker-exercise-16.1",
    "title": "CPSC 330 Lecture 16: Recommender Systems",
    "section": "iClicker Exercise 16.1",
    "text": "iClicker Exercise 16.1\nSelect all of the following statements which are True (iClicker)\n\n\nIn the context of recommendation systems, the shapes of validation utility matrix and train utility matrix are the same.\n\n\nRMSE perfectly captures what we want to measure in the context of recommendation systems.\n\n\nIt would be reasonable to impute missing values in the utility matrix by taking the average of the ratings given to an item by similar users.\n\n\nIn KNN type imputation, if a user has not rated any items yet, a reasonable strategy would be recommending them the most popular item."
  },
  {
    "objectID": "slides-07.html#announcements",
    "href": "slides-07.html#announcements",
    "title": "Lecture 7: Linear models",
    "section": "Announcements",
    "text": "Announcements\n\nLearning Log 01 is due on Sunday!\nHW3 is due tonight!\nHW4 is due Monday night\nReminder about Midterm 1 next week!"
  },
  {
    "objectID": "slides-07.html#iclicker-exercise-6.1",
    "href": "slides-07.html#iclicker-exercise-6.1",
    "title": "Lecture 7: Linear models",
    "section": "(iClicker) Exercise 6.1",
    "text": "(iClicker) Exercise 6.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nYou could carry out cross-validation by passing a ColumnTransformer object to cross_validate.\n\n\nAfter applying column transformer, the order of the columns in the transformed data has to be the same as the order of the columns in the original data.\n\n\nAfter applying a column transformer, the transformed data is always going to be of different shape than the original data.\n\n\nWhen you call fit_transform on a ColumnTransformer object, you get a numpy ndarray.\n\n\n\niClicker 6.1\nA. False, column transfer to pipeline. There is no estimator attached to ColumnTransfer\nB. False, numeric, binary, ordinal, categorical etc…Can also use this to remove columns\nC. False, often it will be different, but not always\nD. True, just an ndarray, not a data frame"
  },
  {
    "objectID": "slides-07.html#notes-on-preprocessing",
    "href": "slides-07.html#notes-on-preprocessing",
    "title": "Lecture 7: Linear models",
    "section": "Notes on preprocessing",
    "text": "Notes on preprocessing\n\nThere is no one-size-fits-all solution in data preprocessing, and decisions often involve a degree of subjectivity.\n\nExploratory data analysis and domain knowledge inform these decisions\n\nAlways consider the specific goals of your project when deciding how to encode features."
  },
  {
    "objectID": "slides-07.html#alternative-methods-for-scaling-reference",
    "href": "slides-07.html#alternative-methods-for-scaling-reference",
    "title": "Lecture 7: Linear models",
    "section": "Alternative methods for scaling (Reference)",
    "text": "Alternative methods for scaling (Reference)\n\nStandardScaler\n\nGood choice when the column follows a normal distribution or a distribution somewhat like a normal distribution.\n\nMinMaxScaler: Transform each feature to a desired range. Appropriate when\n\nGood choice for features such as human age, where there is a fixed range of values and the feature is uniformly distributed across the range\n\nNormalizer: Works on rows rather than columns. Normalize examples individually to unit norm.\n\nGood choice for frequency-type data\n\nLog scaling\n\nGood choice for features such as ratings per movies (power law distribution; a few movies have lots of ratings but most movies have very few ratings)\n\n…"
  },
  {
    "objectID": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding",
    "href": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding",
    "title": "Lecture 7: Linear models",
    "section": "Ordinal encoding vs. One-hot encoding",
    "text": "Ordinal encoding vs. One-hot encoding\n\nOrdinal Encoding: Encodes categorical features as an integer array.\nOne-hot Encoding: Creates binary columns for each category’s presence.\nSometimes how we encode a specific feature depends upon the context."
  },
  {
    "objectID": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding-reference",
    "href": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding-reference",
    "title": "Lecture 7: Linear models",
    "section": "Ordinal encoding vs. One-hot encoding (Reference)",
    "text": "Ordinal encoding vs. One-hot encoding (Reference)\n\nConsider weather feature and its four categories: Sunny (☀️), Cloudy (🌥️), Rainy (⛈️), Snowy (❄️)\nWhich encoding would you use in each of the following scenarios?\n\nPredicting traffic volume\nPredicting severity of weather-related road incidents"
  },
  {
    "objectID": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding-reference-1",
    "href": "slides-07.html#ordinal-encoding-vs.-one-hot-encoding-reference-1",
    "title": "Lecture 7: Linear models",
    "section": "Ordinal encoding vs. One-hot encoding (Reference)",
    "text": "Ordinal encoding vs. One-hot encoding (Reference)\n\nConsider weather feature and its four categories: Sunny (☀️), Cloudy (🌥️), Rainy (⛈️), Snowy (❄️)\nPredicting traffic volume: Using one-hot encoding would make sense here because the impact of different weather conditions on traffic volume does not necessarily follow a clear order and different weather conditions could have very distinct effects.\nPredicting severity of weather-related road incidents: An ordinal encoding might be more appropriate if you define your weather categories from least to most severe as this could correlate directly with the likelihood or severity of incidents."
  },
  {
    "objectID": "slides-07.html#handle_unknown-ignore-of-onehotencoder",
    "href": "slides-07.html#handle_unknown-ignore-of-onehotencoder",
    "title": "Lecture 7: Linear models",
    "section": "handle_unknown = \"ignore\" of OneHotEncoder",
    "text": "handle_unknown = \"ignore\" of OneHotEncoder\n\nUse handle_unknown='ignore' with OneHotEncoder to safely ignore unseen categories during transform.\n\n\n\n\n\n\n\nQuestion for you to consider in your Group\n\n\nHow would you determine whether it is reasonable or not to set\nhandle_unknown = \"ignore\"?"
  },
  {
    "objectID": "slides-07.html#handle_unknown-ignore-of-onehotencoder-1",
    "href": "slides-07.html#handle_unknown-ignore-of-onehotencoder-1",
    "title": "Lecture 7: Linear models",
    "section": "handle_unknown = \"ignore\" of OneHotEncoder",
    "text": "handle_unknown = \"ignore\" of OneHotEncoder\n\nExample 1: Suppose you are building a model to predict customer behavior (e.g., purchase likelihood) based on features like location, device_type, and product_category. During training, you have observed a set of categories for product_category, but in the future, new product categories might be added.\n\n\n\nExample 2: You’re building a model to predict disease diagnosis based on symptoms, where each symptom is categorized (e.g., fever, headache, nausea)."
  },
  {
    "objectID": "slides-07.html#handle_unknown-ignore-of-onehotencoder-2",
    "href": "slides-07.html#handle_unknown-ignore-of-onehotencoder-2",
    "title": "Lecture 7: Linear models",
    "section": "handle_unknown = \"ignore\" of OneHotEncoder",
    "text": "handle_unknown = \"ignore\" of OneHotEncoder\n\nReasonable use: When unseen categories are less likely to impact the model’s prediction accuracy (e.g., product categories in e-commerce), and you prefer to avoid breaking the model.\nNot-so-reasonable use: When unseen categories could provide critical new information that could significantly alter predictions (e.g., in medical diagnostics), ignoring them could result in a poor or dangerous outcome."
  },
  {
    "objectID": "slides-07.html#dropif_binary-argument-of-onehotencoder-reference",
    "href": "slides-07.html#dropif_binary-argument-of-onehotencoder-reference",
    "title": "Lecture 7: Linear models",
    "section": "drop=\"if_binary\" argument of OneHotEncoder (Reference)",
    "text": "drop=\"if_binary\" argument of OneHotEncoder (Reference)\n\ndrop=‘if_binary’ argument in OneHotEncoder:\nReduces redundancy by dropping one of the columns if the feature is binary."
  },
  {
    "objectID": "slides-07.html#categorical-variables-with-too-many-categories",
    "href": "slides-07.html#categorical-variables-with-too-many-categories",
    "title": "Lecture 7: Linear models",
    "section": "Categorical variables with too many categories",
    "text": "Categorical variables with too many categories\n\nStrategies for categorical variables with too many categories:\n\nDimensionality reduction techniques\nBucketing categories into ‘others’\nClustering or grouping categories manually\nOnly considering top-N categories\n…"
  },
  {
    "objectID": "slides-07.html#dealing-with-text-features",
    "href": "slides-07.html#dealing-with-text-features",
    "title": "Lecture 7: Linear models",
    "section": "Dealing with text features",
    "text": "Dealing with text features\n\nPreprocessing text to fit into machine learning models using text vectorization.\nBag of words representation"
  },
  {
    "objectID": "slides-07.html#sklearn-countvectorizer",
    "href": "slides-07.html#sklearn-countvectorizer",
    "title": "Lecture 7: Linear models",
    "section": "sklearn CountVectorizer",
    "text": "sklearn CountVectorizer\n\nUse scikit-learn’s CountVectorizer to encode text data\nCountVectorizer: Transforms text into a matrix of token counts\nImportant parameters:\n\nmax_features: Control the number of features used in the model\nmax_df, min_df: Control document frequency thresholds\nngram_range: Defines the range of n-grams to be extracted\nstop_words: Enables the removal of common words that are typically uninformative in most applications, such as “and”, “the”, etc."
  },
  {
    "objectID": "slides-07.html#incorporating-text-features-in-a-machine-learning-pipeline",
    "href": "slides-07.html#incorporating-text-features-in-a-machine-learning-pipeline",
    "title": "Lecture 7: Linear models",
    "section": "Incorporating text features in a machine learning pipeline",
    "text": "Incorporating text features in a machine learning pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\ntext_pipeline = make_pipeline(\n    CountVectorizer(),\n    SVC()\n)"
  },
  {
    "objectID": "slides-07.html#iclicker-exercise-6.2",
    "href": "slides-07.html#iclicker-exercise-6.2",
    "title": "Lecture 7: Linear models",
    "section": "(iClicker) Exercise 6.2",
    "text": "(iClicker) Exercise 6.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nhandle_unknown=\"ignore\" would treat all unknown categories equally.\n\n\nAs you increase the value for max_features hyperparameter of CountVectorizer the training score is likely to go up.\n\n\nSuppose you are encoding text data using CountVectorizer. If you encounter a word in the validation or the test split that’s not available in the training data, we’ll get an error.\n\n\nIn the code below, inside cross_validate, each fold might have slightly different number of features (columns) in the fold.\n\n\npipe = (CountVectorizer(), SVC())\ncross_validate(pipe, X_train, y_train)"
  },
  {
    "objectID": "slides-07.html#recap-dealing-with-text-features",
    "href": "slides-07.html#recap-dealing-with-text-features",
    "title": "Lecture 7: Linear models",
    "section": "Recap: Dealing with text features",
    "text": "Recap: Dealing with text features\n\nPreprocessing text to fit into machine learning models using text vectorization.\nBag of words representation"
  },
  {
    "objectID": "slides-07.html#recap-sklearn-countvectorizer",
    "href": "slides-07.html#recap-sklearn-countvectorizer",
    "title": "Lecture 7: Linear models",
    "section": "Recap: sklearn CountVectorizer",
    "text": "Recap: sklearn CountVectorizer\n\nUse scikit-learn’s CountVectorizer to encode text data\nCountVectorizer: Transforms text into a matrix of token counts\nImportant parameters:\n\nmax_features: Control the number of features used in the model\nmax_df, min_df: Control document frequency thresholds\nngram_range: Defines the range of n-grams to be extracted\nstop_words: Enables the removal of common words that are typically uninformative in most applications, such as “and”, “the”, etc."
  },
  {
    "objectID": "slides-07.html#recap-incorporating-text-features-in-a-machine-learning-pipeline",
    "href": "slides-07.html#recap-incorporating-text-features-in-a-machine-learning-pipeline",
    "title": "Lecture 7: Linear models",
    "section": "Recap: Incorporating text features in a machine learning pipeline",
    "text": "Recap: Incorporating text features in a machine learning pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\ntext_pipeline = make_pipeline(\n    CountVectorizer(),\n    SVC()\n)"
  },
  {
    "objectID": "slides-07.html#ridge-vs.-linearregression",
    "href": "slides-07.html#ridge-vs.-linearregression",
    "title": "Lecture 7: Linear models",
    "section": "Ridge vs. LinearRegression",
    "text": "Ridge vs. LinearRegression\n\nOrdinary linear regression is sensitive to multicolinearity and overfitting\nMulticolinearity: Overlapping and redundant features. Most of the real-world datasets have colinear features.\n\nLinear regression may produce large and unstable coefficients in such cases.\nRidge adds a parameter to control the complexity of a model. Finds a line that balances fit and prevents overly large coefficients."
  },
  {
    "objectID": "slides-07.html#when-to-use-what",
    "href": "slides-07.html#when-to-use-what",
    "title": "Lecture 7: Linear models",
    "section": "When to use what?",
    "text": "When to use what?\n\nLinearRegression\n\nWhen interpretability is key, and no multicollinearity exists\n\nRidge\n\nWhen you have multicollinearity (highly correlated features).\nWhen you want to prevent overfitting in linear models.\nWhen model stability is important.\n\nIn this course, we’ll use Ridge."
  },
  {
    "objectID": "slides-07.html#logistic-regression",
    "href": "slides-07.html#logistic-regression",
    "title": "Lecture 7: Linear models",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nSuppose your target is binary: pass or fail\nLogistic regression is used for such binary classification tasks.\n\nLogistic regression predicts a probability that the given example belongs to a particular class.\nIt uses Sigmoid function to map any real-valued input into a value between 0 and 1, representing the probability of a specific outcome.\nA threshold (usually 0.5) is applied to the predicted probability to decide the final class label."
  },
  {
    "objectID": "slides-07.html#logistic-regression-decision-boundary",
    "href": "slides-07.html#logistic-regression-decision-boundary",
    "title": "Lecture 7: Linear models",
    "section": "Logistic regression: Decision boundary",
    "text": "Logistic regression: Decision boundary\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe decision boundary is the point on the x-axis where the corresponding predicted probability on the y-axis is 0.5."
  },
  {
    "objectID": "slides-07.html#parametric-vs.-non-parametric-models-high-level",
    "href": "slides-07.html#parametric-vs.-non-parametric-models-high-level",
    "title": "Lecture 7: Linear models",
    "section": "Parametric vs. non-Parametric models (high-level)",
    "text": "Parametric vs. non-Parametric models (high-level)\n\nImagine you are training a logistic regression model. For each of the following scenarios, identify how many parameters (weights and biases) will be learned.\nScenario 1: 100 features and 1,000 examples\nScenario 2: 100 features and 1 million examples"
  },
  {
    "objectID": "slides-07.html#parametric-vs.-non-parametric-models-high-level-1",
    "href": "slides-07.html#parametric-vs.-non-parametric-models-high-level-1",
    "title": "Lecture 7: Linear models",
    "section": "Parametric vs. non-Parametric models (high-level)",
    "text": "Parametric vs. non-Parametric models (high-level)\n\n\nParametric\n\nExamples: Logistic regression, linear regression, linear SVM\n\nModels with a fixed number of parameters, regardless of the dataset size\nSimple, computationally efficient, less prone to overfitting\nLess flexible, may not capture complex relationships\n\n\nNon parametric\n\nExamples: KNN, SVM RBF, Decision tree with no specific depth specified\nModels where the number of parameters grows with the dataset size. They do not assume a fixed form for the functions being learned.\nFlexible, can adapt to complex patterns\nComputationally expensive, risk of overfitting with noisy data"
  },
  {
    "objectID": "slides-07.html#iclicker-exercise-7.1",
    "href": "slides-07.html#iclicker-exercise-7.1",
    "title": "Lecture 7: Linear models",
    "section": "(iClicker) Exercise 7.1",
    "text": "(iClicker) Exercise 7.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIncreasing the hyperparameter alpha of Ridge is likely to decrease model complexity.\n\n\nRidge can be used with datasets that have multiple features.\n\n\nWith Ridge, we learn one coefficient per training example.\n\n\nIf you train a linear regression model on a 2-dimensional problem (2 features), the model will learn 3 parameters: one for each feature and one for the bias term."
  },
  {
    "objectID": "slides-07.html#iclicker-exercise-7.2",
    "href": "slides-07.html#iclicker-exercise-7.2",
    "title": "Lecture 7: Linear models",
    "section": "(iClicker) Exercise 7.2",
    "text": "(iClicker) Exercise 7.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIncreasing logistic regression’s C hyperparameter increases model complexity.\n\n\nThe raw output score can be used to calculate the probability score for a given prediction.\n\n\nFor linear classifier trained on \\(d\\) features, the decision boundary is a \\(d-1\\)-dimensional hyperplane.\n\n\nA linear model is likely to be uncertain about the data points close to the decision boundary."
  },
  {
    "objectID": "slides-07.html#group-work-class-demo-live-coding",
    "href": "slides-07.html#group-work-class-demo-live-coding",
    "title": "Lecture 7: Linear models",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-13.html#continue-with-lecture-13-demo",
    "href": "slides-13.html#continue-with-lecture-13-demo",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Continue with Lecture 13 demo",
    "text": "Continue with Lecture 13 demo\n\nSHAP!"
  },
  {
    "objectID": "slides-13.html#break",
    "href": "slides-13.html#break",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Break",
    "text": "Break\nLet’s take a 10-min break"
  },
  {
    "objectID": "slides-13.html#iclicker-exercise-14.0",
    "href": "slides-13.html#iclicker-exercise-14.0",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "iClicker Exercise 14.0",
    "text": "iClicker Exercise 14.0\niClicker cloud join link: https://join.iclicker.com/YJHS\nSuppose you are working on a machine learning project. If you have to prioritize one of the following in your project which of the following would it be?\n\nThe quality and size of the data\nMost recent deep neural network model\nMost recent optimization algorithm"
  },
  {
    "objectID": "slides-13.html#discussion-question",
    "href": "slides-13.html#discussion-question",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Discussion question",
    "text": "Discussion question\n\nSuppose we want to predict whether a flight will arrive on time or be delayed. We have a dataset with the following information about flights:\n\nDeparture Time\nExpected Duration of Flight (in minutes)\n\n\nUpon analyzing the data, you notice a pattern: flights tend to be delayed more often during the evening rush hours. What feature could be valuable to add for this prediction task?"
  },
  {
    "objectID": "slides-13.html#garbage-in-garbage-out.",
    "href": "slides-13.html#garbage-in-garbage-out.",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Garbage in, garbage out.",
    "text": "Garbage in, garbage out.\n\nModel building is interesting. But in your machine learning projects, you’ll be spending more than half of your time on data preparation, feature engineering, and transformations.\nThe quality of the data is important. Your model is only as good as your data."
  },
  {
    "objectID": "slides-13.html#activity-measuring-quality-of-the-data",
    "href": "slides-13.html#activity-measuring-quality-of-the-data",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Activity: Measuring quality of the data",
    "text": "Activity: Measuring quality of the data\n\nDiscuss some attributes of good- and bad-quality data"
  },
  {
    "objectID": "slides-13.html#what-is-feature-engineering",
    "href": "slides-13.html#what-is-feature-engineering",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "What is feature engineering?",
    "text": "What is feature engineering?\n\nFeature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data. - Jason Brownlee\n\n\nBetter features: more flexibility, higher score, we can get by with simple and more interpretable models.\nIf your features, i.e., representation is bad, whatever fancier model you build is not going to help."
  },
  {
    "objectID": "slides-13.html#some-quotes-on-feature-engineering",
    "href": "slides-13.html#some-quotes-on-feature-engineering",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Some quotes on feature engineering",
    "text": "Some quotes on feature engineering\nA quote by Pedro Domingos A Few Useful Things to Know About Machine Learning\n\n… At the end of the day, some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used."
  },
  {
    "objectID": "slides-13.html#some-quotes-on-feature-engineering-1",
    "href": "slides-13.html#some-quotes-on-feature-engineering-1",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Some quotes on feature engineering",
    "text": "Some quotes on feature engineering\nA quote by Andrew Ng, Machine Learning and AI via Brain simulations\n\nComing up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering."
  },
  {
    "objectID": "slides-13.html#better-features-usually-help-more-than-a-better-model",
    "href": "slides-13.html#better-features-usually-help-more-than-a-better-model",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Better features usually help more than a better model",
    "text": "Better features usually help more than a better model\n\nGood features would ideally:\n\ncapture most important aspects of the problem\nallow learning with few examples\ngeneralize to new scenarios.\n\nThere is a trade-off between simple and expressive features:\n\nWith simple features overfitting risk is low, but scores might be low.\nWith complicated features scores can be high, but so is overfitting risk."
  },
  {
    "objectID": "slides-13.html#the-best-features-may-be-dependent-on-the-model-you-use",
    "href": "slides-13.html#the-best-features-may-be-dependent-on-the-model-you-use",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "The best features may be dependent on the model you use",
    "text": "The best features may be dependent on the model you use\n\nExamples:\n\nFor counting-based methods like decision trees separate relevant groups of variable values\n\nDiscretization makes sense\n\nFor distance-based methods like KNN, we want different class labels to be “far”.\n\nStandardization\n\nFor regression-based methods like linear regression, we want targets to have a linear dependency on features."
  },
  {
    "objectID": "slides-13.html#motivating-feature-engineering",
    "href": "slides-13.html#motivating-feature-engineering",
    "title": "CPSC 330 Lecture 13: Feature Engineering and Selection",
    "section": "Motivating Feature Engineering",
    "text": "Motivating Feature Engineering\nQuestions:\n\nWhat are two possible ways we could “engineer” features?\n\nThink broadly and philosophically rathern than an implementation…"
  },
  {
    "objectID": "slides-01.html#introductions",
    "href": "slides-01.html#introductions",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "🤝 Introductions ! 🤝",
    "text": "🤝 Introductions ! 🤝"
  },
  {
    "objectID": "slides-01.html#about-your-instructor",
    "href": "slides-01.html#about-your-instructor",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "About your instructor",
    "text": "About your instructor"
  },
  {
    "objectID": "slides-01.html#about-my-research-interests",
    "href": "slides-01.html#about-my-research-interests",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "About my research interests",
    "text": "About my research interests"
  },
  {
    "objectID": "slides-01.html#group-work-in-this-class",
    "href": "slides-01.html#group-work-in-this-class",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Group work in this class",
    "text": "Group work in this class\nThis term we will try to work in “Pods” of 3-5 …\nResearch shows that there is tremendous benefits in students working (and struggling) together!\nStudents ask better and more insightful questions, engage more deeply with the work, and it adds a social element to class.\nWe will try this in CPSC 330 this term!"
  },
  {
    "objectID": "slides-01.html#group-work-in-this-class-1",
    "href": "slides-01.html#group-work-in-this-class-1",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Group work in this class",
    "text": "Group work in this class\nUnderstandably, not everyone is a fan of group work - I understand that!\nSo you will never be forced to work in groups ​​If you would like to opt-out, move to the far left and far right sides of the room so we know you prefer to work individually.\nIf everyone moves to the side of the room, we will re-evaluate this approach 😂\nThere are no marks or points associated with these groups, and everyone should work on their own laptops as well"
  },
  {
    "objectID": "slides-01.html#group-work-pods",
    "href": "slides-01.html#group-work-pods",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Group work: Pods",
    "text": "Group work: Pods\nForm a Pod of 3-5 people sitting close to you.\nEach person should answer the following questions:\n\nPreferred Name,\nYear,\n(intended) Major\nWhy are you taking CPSC 330?\n\nThen, as a group, answer the following question:\nWhat is the most interesting (good or bad) example of Machine Learning in society?"
  },
  {
    "objectID": "slides-01.html#meet-eva-a-fictitious-persona",
    "href": "slides-01.html#meet-eva-a-fictitious-persona",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Meet Eva (a fictitious persona)!",
    "text": "Meet Eva (a fictitious persona)!\n\n\n\n\nEva is among one of you. She has some experience in Python programming. She knows machine learning as a buzz word. During her recent internship, she has developed some interest and curiosity in the field. She wants to learn what is it and how to use it. She is a curious person and usually has a lot of questions!"
  },
  {
    "objectID": "slides-01.html#learning-outcomes",
    "href": "slides-01.html#learning-outcomes",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Learning outcomes",
    "text": "Learning outcomes\nFrom this lecture, you will be able to\n\nExplain the motivation behind study machine learning.\nBriefly describe supervised learning.\nDifferentiate between traditional programming and machine learning.\nAssess whether a given problem is suitable for a machine learning solution.\nNavigate through the course material.\nBe familiar with the policies and how the class is going to run.\nBecome familiar with CPSC 330 and how the course works"
  },
  {
    "objectID": "slides-01.html#about-this-course",
    "href": "slides-01.html#about-this-course",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "About this course",
    "text": "About this course"
  },
  {
    "objectID": "slides-01.html#cpsc-330-website",
    "href": "slides-01.html#cpsc-330-website",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "CPSC 330 website",
    "text": "CPSC 330 website\n\nCourse Jupyter book: https://ubc-cs.github.io/cpsc330-2025S1\nCourse GitHub repository: https://github.com/UBC-CS/cpsc330-2025S1\n\n\n\n\n\n\n\nImportant\n\n\nCourse website: https://ubc-cs.github.io/cpsc330-2025S1 is the most important link. You can access the course website from Canvas.\n\nPlease read everything on there!\nYou can find the source code for everything we do here: https://ubc-cs.github.io/cpsc330-2025S1.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nMake sure you go through the syllabus thoroughly and complete the syllabus quiz before Friday’s class!"
  },
  {
    "objectID": "slides-01.html#asking-questions-during-class",
    "href": "slides-01.html#asking-questions-during-class",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Asking questions during class",
    "text": "Asking questions during class\nYou are welcome to ask questions by raising your hand!\nIf you would prefer to write notes and ask questions later, you are more than welcome to do that also! Use Piazza."
  },
  {
    "objectID": "slides-01.html#registration-waitlist-and-prerequisites",
    "href": "slides-01.html#registration-waitlist-and-prerequisites",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Registration, waitlist and prerequisites",
    "text": "Registration, waitlist and prerequisites\n\n\n\n\n\n\nImportant\n\n\nPlease go through this document carefully before contacting your instructors about these issues. Even then, we are very unlikely to be able to help with registration, waitlist or prerequisite issues.\n\n\n\n\nIf you are on waitlist and if you’d like to try your chances, you should be able to access Canvas and Ed Discussion.\n\nIf you’re unable to make it this time, there will be multiple sections of this course offered next semester and then again in the spring."
  },
  {
    "objectID": "slides-01.html#lecture-format",
    "href": "slides-01.html#lecture-format",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Lecture format",
    "text": "Lecture format\n\nIn person lectures M,W,F from 10 AM to 1 PM.\nThere will be videos to watch before every lecture. You will find the list of pre-watch videos in the schedule on the course webpage.\nWe will also try to work on some questions and exercises together during the class.\nAll materials will be posted in this GitHub repository.  \n\nYou may attend any tutorials or office hours your want, regardless of in which/whether you’re registered."
  },
  {
    "objectID": "slides-01.html#home-work-assignments",
    "href": "slides-01.html#home-work-assignments",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Home work assignments",
    "text": "Home work assignments\n\nFirst homework assignment is due Friday May 16th, at 6 PM. This is a relatively straightforward assignment on Python. If you struggle with this assignment then that could be a sign that you will struggle later on in the course.\n\nYou must do the first two homework assignments on your own."
  },
  {
    "objectID": "slides-01.html#exams",
    "href": "slides-01.html#exams",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Exams",
    "text": "Exams\n\nWe’ll have two self-scheduled midterms over a few day window and one final exam in Computer-based Testing Facility (CBTF)."
  },
  {
    "objectID": "slides-01.html#course-structure",
    "href": "slides-01.html#course-structure",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Course structure",
    "text": "Course structure\n\nPart I: Introduction, ML fundamentals, preprocessing, midterm 1\nPart II: Unsupervised learning, transfer learning, common special cases, midterm 1\nPart III: Communication and ethics\n\nML skills are not beneficial if you can’t use them responsibly and communicate your results. In this module we’ll talk about these aspects. ## Code of conduct\n\nOur main forum for getting help will be Ed Discussion.\n\n\n\n\n\n\n\nImportant\n\n\nPlease read this entire document about asking for help. TLDR: Be nice."
  },
  {
    "objectID": "slides-01.html#homework-format-jupyter-lab-notebooks",
    "href": "slides-01.html#homework-format-jupyter-lab-notebooks",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Homework format: Jupyter lab notebooks",
    "text": "Homework format: Jupyter lab notebooks\n\nOur notes are created in a Jupyter notebook, with file extension .ipynb.\nAlso, you will complete your homework assignments using Jupyter notebooks.\nConfusingly, “Jupyter notebook” is also the original application that opens .ipynb files - but has since been replaced by Jupyter lab.\n\nI am using Jupyter lab, some things might not work with the Jupyter notebook application.\nYou can also open these files in Visual Studio Code."
  },
  {
    "objectID": "slides-01.html#jupyter-lab-notebooks",
    "href": "slides-01.html#jupyter-lab-notebooks",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Jupyter lab notebooks",
    "text": "Jupyter lab notebooks\n\nNotebooks contain a mix of code, code output, markdown-formatted text (including LaTeX equations), and more.\nWhen you open a Jupyter notebook in one of these apps, the document is “live”, meaning you can run the code.\n\nFor example:\n\n1 + 1\n\n2\n\n\n\nx = [1, 2, 3]\nx[0] = 9999\nx\n\n[9999, 2, 3]"
  },
  {
    "objectID": "slides-01.html#more-about-jupyter-lab",
    "href": "slides-01.html#more-about-jupyter-lab",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "More about Jupyter lab",
    "text": "More about Jupyter lab\n\nBy default, Jupyter prints out the result of the last line of code, so you don’t need as many print statements.\nIn addition to the “live” notebooks, Jupyter notebooks can be statically rendered in the web browser, e.g. this.\n\nThis can be convenient for quick read-only access, without needing to launch the Jupyter notebook/lab application.\nBut you need to launch the app properly to interact with the notebooks."
  },
  {
    "objectID": "slides-01.html#lecture-notes",
    "href": "slides-01.html#lecture-notes",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Lecture notes",
    "text": "Lecture notes\n\nAll the lectures from last year are available here.\nWe cannot promise anything will stay the same from last year to this year, so read them in advance at your own risk.\nA “finalized” version will be pushed to GitHub and the Jupyter book right before each class.\nEach instructor will have slightly adapted versions of notes to present slides during lectures.\n\nYou will find the link to these slides in our repository: https://github.com/UBC-CS/cpsc330-2025S1/tree/main/lectures/103-Firas-lectures"
  },
  {
    "objectID": "slides-01.html#grades",
    "href": "slides-01.html#grades",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Grades",
    "text": "Grades\n\nThe grading breakdown is here.\nThe policy on challenging grades is here."
  },
  {
    "objectID": "slides-01.html#setting-up-your-computer-for-the-course",
    "href": "slides-01.html#setting-up-your-computer-for-the-course",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Setting up your computer for the course",
    "text": "Setting up your computer for the course"
  },
  {
    "objectID": "slides-01.html#recommended-browser-and-tools",
    "href": "slides-01.html#recommended-browser-and-tools",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Recommended browser and tools",
    "text": "Recommended browser and tools\n\nYou can install Chrome here.\nYou can install Firefox here.\n\nIn this course, we will primarily be using Python , git, GitHub, Canvas, Gradescope, Piazza, and PrairieLearn."
  },
  {
    "objectID": "slides-01.html#course-conda-environment",
    "href": "slides-01.html#course-conda-environment",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Course conda environment",
    "text": "Course conda environment\n\nFollow the setup instructions here to create a course conda environment on your computer.\nIf you do not have your computer with you, you can partner up with someone and set up your own computer later."
  },
  {
    "objectID": "slides-01.html#python-requirementsresources",
    "href": "slides-01.html#python-requirementsresources",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Python requirements/resources",
    "text": "Python requirements/resources\nWe will primarily use Python in this course.\nHere is the basic Python knowledge you’ll need for the course:\n\nBasic Python programming\nNumpy\nPandas\nBasic matplotlib\nSparse matrices\n\nHomework 1 is all about Python.\n\n\n\n\n\n\nNote\n\n\nWe do not have time to teach all the Python we need but you can find some useful Python resources here."
  },
  {
    "objectID": "slides-01.html#cpsc-330-vs.-340",
    "href": "slides-01.html#cpsc-330-vs.-340",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "CPSC 330 vs. 340",
    "text": "CPSC 330 vs. 340\nRead https://ubc-cs.github.io/cpsc330-2025S1/docs/330_vs_340.html which explains the difference between two courses.\nTLDR:\n\n340: how do ML models work?\n330: how do I use ML models?\nCPSC 340 has many prerequisites.\nCPSC 340 goes deeper but has a more narrow scope.\nI think CPSC 330 will be more useful if you just plan to apply basic ML."
  },
  {
    "objectID": "slides-01.html#what-is-machine-learning-ml",
    "href": "slides-01.html#what-is-machine-learning-ml",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "What is Machine Learning (ML)?",
    "text": "What is Machine Learning (ML)?"
  },
  {
    "objectID": "slides-01.html#spam-prediction",
    "href": "slides-01.html#spam-prediction",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Spam prediction",
    "text": "Spam prediction\n\nSuppose you are given some data with labelled spam and non-spam messages\n\n\nCodeOutput\n\n\n\nsms_df = pd.read_csv(DATA_DIR + \"spam.csv\", encoding=\"latin-1\")\nsms_df = sms_df.drop(columns = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])\nsms_df = sms_df.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"})\ntrain_df, test_df = train_test_split(sms_df, test_size=0.10, random_state=42)\n\n\n\n\n\n\n\n\n\ntarget\nsms\n\n\n\n\nspam\nLookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\n\n\nham\nAight, I'll hit you up when I get some cash\n\n\nham\nDon no da:)whats you plan?\n\n\nham\nGoing to take your babe out ?\n\n\nham\nNo need lar. Jus testing e phone card. Dunno network not gd i thk. Me waiting 4 my sis 2 finish bathing so i can bathe. Dun disturb u liao u cleaning ur room."
  },
  {
    "objectID": "slides-01.html#traditional-programming-vs.-ml",
    "href": "slides-01.html#traditional-programming-vs.-ml",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Traditional programming vs. ML",
    "text": "Traditional programming vs. ML\n\nImagine writing a Python program for spam identification, i.e., whether a text message or an email is spam or non-spam.\nTraditional programming\n\nCome up with rules using human understanding of spam messages.\nTime consuming and hard to come up with robust set of rules.\n\nMachine learning\n\nCollect large amount of data of spam and non-spam emails and let the machine learning algorithm figure out rules."
  },
  {
    "objectID": "slides-01.html#lets-train-a-model",
    "href": "slides-01.html#lets-train-a-model",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Let’s train a model",
    "text": "Let’s train a model\n\nThere are several packages that help us perform machine learning.\n\n\nX_train, y_train = train_df[\"sms\"], train_df[\"target\"]\nX_test, y_test = test_df[\"sms\"], test_df[\"target\"]\nclf = make_pipeline(CountVectorizer(max_features=5000), LogisticRegression(max_iter=5000))\nclf.fit(X_train, y_train); # Training the model"
  },
  {
    "objectID": "slides-01.html#unseen-messages",
    "href": "slides-01.html#unseen-messages",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Unseen messages",
    "text": "Unseen messages\n\nNow use the trained model to predict targets of unseen messages:\n\n\n\n\n\n\n\n\n\n\nsms\n\n\n\n\n3245\nFunny fact Nobody teaches volcanoes 2 erupt, tsunamis 2 arise, hurricanes 2 sway aroundn no 1 teaches hw 2 choose a wife Natural disasters just happens\n\n\n944\nI sent my scores to sophas and i had to do secondary application for a few schools. I think if you are thinking of applying, do a research on cost also. Contact joke ogunrinde, her school is one m...\n\n\n1044\nWe know someone who you know that fancies you. Call 09058097218 to find out who. POBox 6, LS15HB 150p\n\n\n2484\nOnly if you promise your getting out as SOON as you can. And you'll text me in the morning to let me know you made it in ok."
  },
  {
    "objectID": "slides-01.html#predicting-on-unseen-data",
    "href": "slides-01.html#predicting-on-unseen-data",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Predicting on unseen data",
    "text": "Predicting on unseen data\nThe model is accurately predicting labels for the unseen text messages above!\n\n\n\n\n\n\n\n \nsms\nspam_predictions\n\n\n\n\n3245\nFunny fact Nobody teaches volcanoes 2 erupt, tsunamis 2 arise, hurricanes 2 sway aroundn no 1 teaches hw 2 choose a wife Natural disasters just happens\nham\n\n\n944\nI sent my scores to sophas and i had to do secondary application for a few schools. I think if you are thinking of applying, do a research on cost also. Contact joke ogunrinde, her school is one me the less expensive ones\nham\n\n\n1044\nWe know someone who you know that fancies you. Call 09058097218 to find out who. POBox 6, LS15HB 150p\nspam\n\n\n2484\nOnly if you promise your getting out as SOON as you can. And you'll text me in the morning to let me know you made it in ok.\nham"
  },
  {
    "objectID": "slides-01.html#a-different-way-to-solve-problems",
    "href": "slides-01.html#a-different-way-to-solve-problems",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "A different way to solve problems",
    "text": "A different way to solve problems\nMachine learning uses computer programs to model data. It can be used to extract hidden patterns, make predictions in new situation, or generate novel content.\n\nA field of study that gives computers the ability to learn without being explicitly programmed.  – Arthur Samuel (1959)"
  },
  {
    "objectID": "slides-01.html#ml-vs.-traditional-programming",
    "href": "slides-01.html#ml-vs.-traditional-programming",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "ML vs. traditional programming",
    "text": "ML vs. traditional programming\n\nWith machine learning, you’re likely to\n\nSave time\nCustomize and scale products"
  },
  {
    "objectID": "slides-01.html#prevalence-of-ml",
    "href": "slides-01.html#prevalence-of-ml",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Prevalence of ML",
    "text": "Prevalence of ML\nLet’s look at some examples."
  },
  {
    "objectID": "slides-01.html#activity-for-what-type-of-problems-ml-is-appropriate-5-mins",
    "href": "slides-01.html#activity-for-what-type-of-problems-ml-is-appropriate-5-mins",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Activity: For what type of problems ML is appropriate? (~5 mins)",
    "text": "Activity: For what type of problems ML is appropriate? (~5 mins)\nDiscuss with your neighbour for which of the following problems you would use machine learning\n\nFinding a list of prime numbers up to a limit\nGiven an image, automatically identifying and labeling objects in the image\nFinding the distance between two nodes in a graph"
  },
  {
    "objectID": "slides-01.html#types-of-machine-learning",
    "href": "slides-01.html#types-of-machine-learning",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Types of machine learning",
    "text": "Types of machine learning\nHere are some typical learning problems.\n\nSupervised learning (Gmail spam filtering)\n\nTraining a model from input data and its corresponding targets to predict targets for new examples.\n\n\nUnsupervised learning (Google News)\n\nTraining a model to find patterns in a dataset, typically an unlabeled dataset.\n\nReinforcement learning (AlphaGo)\n\nA family of algorithms for finding suitable actions to take in a given situation in order to maximize a reward.\n\nRecommendation systems (Amazon item recommendation system)\n\nPredict the “rating” or “preference” a user would give to an item."
  },
  {
    "objectID": "slides-01.html#what-is-supervised-learning",
    "href": "slides-01.html#what-is-supervised-learning",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "What is supervised learning?",
    "text": "What is supervised learning?\n\nTraining data comprises a set of observations (\\(X\\)) and their corresponding targets (\\(y\\)).\nWe wish to find a model function \\(f\\) that relates \\(X\\) to \\(y\\).\nWe use the model function to predict targets of new examples."
  },
  {
    "objectID": "slides-01.html#evas-questions",
    "href": "slides-01.html#evas-questions",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "🤔 Eva’s questions",
    "text": "🤔 Eva’s questions\n\n\nAt this point, Eva is wondering about many questions.\n\nHow are we exactly “learning” whether a message is spam and ham?\nAre we expected to get correct predictions for all possible messages? How does it predict the label for a message it has not seen before?\n\nWhat if the model mis-labels an unseen example? For instance, what if the model incorrectly predicts a non-spam as a spam? What would be the consequences?\nHow do we measure the success or failure of spam identification?\nIf you want to use this model in the wild, how do you know how reliable it is?\n\nWould it be useful to know how confident the model is about the predictions rather than just a yes or a no?\n\nIt’s great to think about these questions right now. But Eva has to be patient. By the end of this course you’ll know answers to many of these questions!"
  },
  {
    "objectID": "slides-01.html#looking-ahead-to-next-class",
    "href": "slides-01.html#looking-ahead-to-next-class",
    "title": "Lecture 1: Introduction to CPSC 330",
    "section": "Looking ahead to next class",
    "text": "Looking ahead to next class\nIt is very important that you watch the assigned pre-lecture videos before class!"
  },
  {
    "objectID": "slides-19.html#announcements",
    "href": "slides-19.html#announcements",
    "title": "CPSC 330 Lecture 19: Time series",
    "section": "Announcements",
    "text": "Announcements\n\nNo new announcements today!"
  },
  {
    "objectID": "slides-19.html#motivation",
    "href": "slides-19.html#motivation",
    "title": "CPSC 330 Lecture 19: Time series",
    "section": "Motivation",
    "text": "Motivation\n\nTime series is a collection of data points indexed in time order.\nTime series is everywhere:\n\nPhysical sciences (e.g., weather forecasting)\n\nEconomics, finance (e.g., stocks, market trends)\nEngineering (e.g., energy consumption)\nSocial sciences\nSports analytics"
  },
  {
    "objectID": "slides-19.html#applying-existing-methods",
    "href": "slides-19.html#applying-existing-methods",
    "title": "CPSC 330 Lecture 19: Time series",
    "section": "Applying existing methods",
    "text": "Applying existing methods\nWhat are some challenges we might have with time series data?"
  },
  {
    "objectID": "slides-19.html#dataset",
    "href": "slides-19.html#dataset",
    "title": "CPSC 330 Lecture 19: Time series",
    "section": "Dataset",
    "text": "Dataset\nWe’ll be starting with the CitiBike dataset today"
  },
  {
    "objectID": "slides-10.html#recap-ridge-and-ridgecv",
    "href": "slides-10.html#recap-ridge-and-ridgecv",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "Recap: Ridge and RidgeCV",
    "text": "Recap: Ridge and RidgeCV\n\nRidge Regression: alpha hyperparameter controls model complexity.\nRidgeCV: Ridge regression with built-in cross-validation to find the optimal alpha."
  },
  {
    "objectID": "slides-10.html#recap-alpha-hyperparameter",
    "href": "slides-10.html#recap-alpha-hyperparameter",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "Recap: alpha hyperparameter",
    "text": "Recap: alpha hyperparameter\n\nRole of alpha:\n\nControls model complexity\nHigher alpha: Simpler model, smaller coefficients.\nLower alpha: Complex model, larger coefficients."
  },
  {
    "objectID": "slides-10.html#regression-metrics-mse-rmse-mape",
    "href": "slides-10.html#regression-metrics-mse-rmse-mape",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "Regression metrics: MSE, RMSE, MAPE",
    "text": "Regression metrics: MSE, RMSE, MAPE\n\nMean Squared Error (MSE): Average of the squares of the errors.\nRoot Mean Squared Error (RMSE): Square root of MSE, same units as the target variable.\nMean Absolute Percentage Error (MAPE): Average of the absolute percentage errors."
  },
  {
    "objectID": "slides-10.html#applying-log-transformation-to-the-targets",
    "href": "slides-10.html#applying-log-transformation-to-the-targets",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "Applying log transformation to the targets",
    "text": "Applying log transformation to the targets\n\nSuitable when the target has a wide range and spans several orders of magnitude\n\nExample: counts data such as social media likes or price data\n\nHelps manage skewed data, making patterns more apparent and regression models more effective.\nTransformedTargetRegressor\n\nWraps a regression model and applies a transformation to the target values."
  },
  {
    "objectID": "slides-10.html#iclicker-exercise-10.1",
    "href": "slides-10.html#iclicker-exercise-10.1",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "iClicker Exercise 10.1",
    "text": "iClicker Exercise 10.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nPrice per square foot would be a good feature to add in our X.\n\n\nThe alpha hyperparameter of Ridge has similar interpretation of C hyperparameter of LogisticRegression; higher alpha means more complex model.\n\n\nIn Ridge, smaller alpha means bigger coefficients whereas bigger alpha means smaller coefficients."
  },
  {
    "objectID": "slides-10.html#iclicker-exercise-10.2",
    "href": "slides-10.html#iclicker-exercise-10.2",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "iClicker Exercise 10.2",
    "text": "iClicker Exercise 10.2\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nWe can use still use precision and recall for regression problems but now we have other metrics we can use as well.\n\n\nIn sklearn for regression problems, using r2_score() and .score() (with default values) will produce the same results.\n\n\nRMSE is always going to be non-negative.\n\n\nMSE does not directly provide the information about whether the model is underpredicting or overpredicting.\n\n\nWe can pass multiple scoring metrics to GridSearchCV or RandomizedSearchCV for regression as well as classification problems."
  },
  {
    "objectID": "slides-10.html#group-work-class-demo-live-coding",
    "href": "slides-10.html#group-work-class-demo-live-coding",
    "title": "CPSC 330 Lecture 10: Regression Metrics",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-06.html#data",
    "href": "slides-06.html#data",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Data",
    "text": "Data\n\nX, y = make_blobs(n_samples=100, centers=3, random_state=12, cluster_std=5) # make synthetic data\nX_train_toy, X_test_toy, y_train_toy, y_test_toy = train_test_split(\n    X, y, random_state=5, test_size=0.4) # split it into training and test sets\n# Visualize the training data\nplt.scatter(X_train_toy[:, 0], X_train_toy[:, 1], label=\"Training set\", s=60)\nplt.scatter(\n    X_test_toy[:, 0], X_test_toy[:, 1], color=mglearn.cm2(1), label=\"Test set\", s=60\n)\nplt.legend(loc=\"upper right\")"
  },
  {
    "objectID": "slides-06.html#bad-ml-1",
    "href": "slides-06.html#bad-ml-1",
    "title": "Lecture 6: Column transformer and text features",
    "section": "❌ Bad ML 1",
    "text": "❌ Bad ML 1\n\nWhat’s wrong with the approach below?\n\n\nscaler = StandardScaler() # Creating a scalert object \nscaler.fit(X_train_toy) # Calling fit on the training data \ntrain_scaled = scaler.transform(\n    X_train_toy\n)  # Transforming the training data using the scaler fit on training data\n\nscaler = StandardScaler()  # Creating a separate object for scaling test data\nscaler.fit(X_test_toy)  # Calling fit on the test data\ntest_scaled = scaler.transform(\n    X_test_toy\n)  # Transforming the test data using the scaler fit on test data\n\nknn = KNeighborsClassifier()\nknn.fit(train_scaled, y_train_toy)\nprint(f\"Training score: {knn.score(train_scaled, y_train_toy):.2f}\")\nprint(f\"Test score: {knn.score(test_scaled, y_test_toy):.2f}\") # misleading scores\n\nTraining score: 0.63\nTest score: 0.60"
  },
  {
    "objectID": "slides-06.html#scaling-train-and-test-data-separately",
    "href": "slides-06.html#scaling-train-and-test-data-separately",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Scaling train and test data separately",
    "text": "Scaling train and test data separately"
  },
  {
    "objectID": "slides-06.html#bad-ml-2",
    "href": "slides-06.html#bad-ml-2",
    "title": "Lecture 6: Column transformer and text features",
    "section": "❌ Bad ML 2",
    "text": "❌ Bad ML 2\n\nWhat’s wrong with the approach below?\n\n\n# join the train and test sets back together\nXX = np.vstack((X_train_toy, X_test_toy))\n\nscaler = StandardScaler()\nscaler.fit(XX)\nXX_scaled = scaler.transform(XX)\n\nXX_train = XX_scaled[:X_train_toy.shape[0]]\nXX_test = XX_scaled[X_train_toy.shape[0]:]\n\nknn = KNeighborsClassifier()\nknn.fit(XX_train, y_train_toy)\nprint(f\"Training score: {knn.score(XX_train, y_train_toy):.2f}\")  # Misleading score\nprint(f\"Test score: {knn.score(XX_test, y_test_toy):.2f}\")  # Misleading score\n\nTraining score: 0.63\nTest score: 0.55"
  },
  {
    "objectID": "slides-06.html#bad-ml-3",
    "href": "slides-06.html#bad-ml-3",
    "title": "Lecture 6: Column transformer and text features",
    "section": "❌ Bad ML 3",
    "text": "❌ Bad ML 3\n\nWhat’s wrong with the approach below?\n\n\nknn = KNeighborsClassifier()\n\nscaler = StandardScaler()\nscaler.fit(X_train_toy)\nX_train_scaled = scaler.transform(X_train_toy)\nX_test_scaled = scaler.transform(X_test_toy)\ncross_val_score(knn, X_train_scaled, y_train_toy)\n\narray([0.25      , 0.5       , 0.58333333, 0.58333333, 0.41666667])\n\n\n\nSpeaker notes go here."
  },
  {
    "objectID": "slides-06.html#improper-preprocessing",
    "href": "slides-06.html#improper-preprocessing",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Improper preprocessing",
    "text": "Improper preprocessing"
  },
  {
    "objectID": "slides-06.html#proper-preprocessing",
    "href": "slides-06.html#proper-preprocessing",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Proper preprocessing",
    "text": "Proper preprocessing"
  },
  {
    "objectID": "slides-06.html#recap-sklearn-pipelines",
    "href": "slides-06.html#recap-sklearn-pipelines",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Recap: sklearn Pipelines",
    "text": "Recap: sklearn Pipelines\n\nPipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\nSimplify the code and improves readability.\nReduce the risk of data leakage by ensuring proper transformation of the training and test sets.\nAutomatically apply transformations in sequence.\nExample:\n\nChaining a StandardScaler with a KNeighborsClassifier model.\n\n\n\nfrom sklearn.pipeline import make_pipeline\n\npipe_knn = make_pipeline(StandardScaler(), KNeighborsClassifier())\n\n# Correct way to do cross validation without breaking the golden rule. \ncross_val_score(pipe_knn, X_train_toy, y_train_toy) \n\narray([0.25      , 0.5       , 0.5       , 0.58333333, 0.41666667])"
  },
  {
    "objectID": "slides-06.html#group-work-class-demo-live-coding",
    "href": "slides-06.html#group-work-class-demo-live-coding",
    "title": "Lecture 6: Column transformer and text features",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-06.html#sklearns-columntransformer",
    "href": "slides-06.html#sklearns-columntransformer",
    "title": "Lecture 6: Column transformer and text features",
    "section": "sklearn’s ColumnTransformer",
    "text": "sklearn’s ColumnTransformer\n\nUse ColumnTransformer to build all our transformations together into one object\n\n\n\nUse a column transformer with sklearn pipelines."
  },
  {
    "objectID": "slides-02.html#announcements",
    "href": "slides-02.html#announcements",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Announcements",
    "text": "Announcements\n\nThings due this week\n\nHomework 1 (hw1): Due May 16 17:59 \n\nYou can find the tentative due dates for all deliverables here.\nPlease monitor Ed Discussion (especially pinned posts and instructor posts) for announcements.\nI’ll assume that you’ve watched the pre-lecture videos."
  },
  {
    "objectID": "slides-02.html#surveys",
    "href": "slides-02.html#surveys",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Surveys",
    "text": "Surveys\n\n\nPlease complete the anonymous restaurant survey on Qualtrics here.\nWe will try to analyze this data set in the coming weeks."
  },
  {
    "objectID": "slides-02.html#gradescope",
    "href": "slides-02.html#gradescope",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Gradescope",
    "text": "Gradescope\nMake sure you can submit your assignment before the hw1 due date!\nIt is required for you to work in a GitHub repository, please maintain your GitHub repo up-to-date.\nFor students on the waitlist: Gradescope Entry code is 9KK5ZR."
  },
  {
    "objectID": "slides-02.html#demo-submit-hw1-on-gradescope",
    "href": "slides-02.html#demo-submit-hw1-on-gradescope",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Demo: Submit hw1 on Gradescope",
    "text": "Demo: Submit hw1 on Gradescope\nWe are going to practice submitting HW1 on Gradescope so you all do it at least once!"
  },
  {
    "objectID": "slides-02.html#checklist-for-you-in-the-first-week",
    "href": "slides-02.html#checklist-for-you-in-the-first-week",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Checklist for you in the first week",
    "text": "Checklist for you in the first week\n\nAre you able to access course Canvas shell?\nAre you able to access course forum: Ed Discussion?\nAre you able to access Gradescope? (If not, refer to the Gradescope Student Guide.)\nAre you able to access iClicker Cloud for this course?\nDid you follow the setup instructions here to create a course conda environment on your computer?\nDid you complete the “Getting to know you” survey on Canvas?\nDid you complete the anonymous restaurant survey on Qualtrics?\nAre you almost finished or at least started with homework 1?"
  },
  {
    "objectID": "slides-02.html#suggested-workflow-for-working-with-jupyter-notebooks",
    "href": "slides-02.html#suggested-workflow-for-working-with-jupyter-notebooks",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Suggested Workflow for working with Jupyter Notebooks",
    "text": "Suggested Workflow for working with Jupyter Notebooks\n\nCreate a folder on your computer that will have all the CPSC 330 repos:\n\n~/School/Year3/CPSC330/ &lt;– Consider this your CPSC parent folder\n\nCreate subfolders for: hw, class, practice\nIn the hw folder, you will then clone hw1, hw2, hw3, etc…\nIn the class folder, you will clone the cpsc330-2025S1 repo which contains all the class jupyter notebooks\n\nDo not make any changes to files in this directory/repo, you will have trouble when you pull stuff during each class.\nIf you did make changes, you can reset to the last commit and DESTROY any changes you made (be careful with this command) using: git reset --hard\n\nIn the practice folder, you can copy any notebooks (.ipynb) and files (like data/*.csv) you want to try running locally and experiment"
  },
  {
    "objectID": "slides-02.html#recap-machine-learning-workflow",
    "href": "slides-02.html#recap-machine-learning-workflow",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Recap: Machine learning workflow",
    "text": "Recap: Machine learning workflow\nSupervised machine learning is quite flexible; it can be used on a variety of problems and different kinds of data. Here is a typical workflow of a supervised machine learning systems.\n\n\n\n\n\n\nWe will build machine learning pipelines in this course, focusing on some of the steps above."
  },
  {
    "objectID": "slides-02.html#recap-what-is-ml",
    "href": "slides-02.html#recap-what-is-ml",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Recap: What is ML?",
    "text": "Recap: What is ML?\n\nML uses data to build models that find patterns, make predictions, or generate content.\nIt helps computers learn from data to make decisions.\nNo one model works for every situation."
  },
  {
    "objectID": "slides-02.html#recap-supervised-learning",
    "href": "slides-02.html#recap-supervised-learning",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Recap: Supervised learning",
    "text": "Recap: Supervised learning\n\nWe wish to find a model function \\(f\\) that relates \\(X\\) to \\(y\\).\nWe use the model function to predict targets of new examples.\n\n\n\n\n\n\nIn the first part of this course, we’ll focus on supervised machine learning."
  },
  {
    "objectID": "slides-02.html#iclicker-2.1-terminology",
    "href": "slides-02.html#iclicker-2.1-terminology",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "iClicker 2.1: Terminology",
    "text": "iClicker 2.1: Terminology\niClicker cloud join link: https://join.iclicker.com/YJHS"
  },
  {
    "objectID": "slides-02.html#select-all-of-the-following-statements-which-are-true-iclicker",
    "href": "slides-02.html#select-all-of-the-following-statements-which-are-true-iclicker",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Select all of the following statements which are True (iClicker)",
    "text": "Select all of the following statements which are True (iClicker)\n\nPredicting spam is an example of machine learning.\nPredicting housing prices is not an example of machine learning.\nFor problems such as spelling correction, translation, face recognition, spam identification, if you are a domain expert, it’s usually faster and scalable to come up with a robust set of rules manually rather than building a machine learning model.\nIf you are asked to write a program to find all prime numbers up to a limit, it is better to implement one of the algorithms for doing so rather than using machine learning.\nGoogle News is likely be using machine learning to organize news."
  },
  {
    "objectID": "slides-02.html#iclicker-2.2-supervised-vs-unsupervised",
    "href": "slides-02.html#iclicker-2.2-supervised-vs-unsupervised",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "iClicker 2.2: Supervised vs unsupervised",
    "text": "iClicker 2.2: Supervised vs unsupervised\nClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are examples of supervised machine learning\n\n\nFinding groups of similar properties in a real estate data set.\n\n\nPredicting whether someone will have a heart attack or not on the basis of demographic, diet, and clinical measurement.\n\n\nGrouping articles on different topics from different news sources (something like the Google News app).\n\n\nDetecting credit card fraud based on examples of fraudulent and non-fraudulent transactions.\n\n\nGiven some measure of employee performance, identify the key factors which are likely to influence their performance."
  },
  {
    "objectID": "slides-02.html#iclicker-2.3-classification-vs.-regression",
    "href": "slides-02.html#iclicker-2.3-classification-vs.-regression",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "iClicker 2.3: Classification vs. Regression",
    "text": "iClicker 2.3: Classification vs. Regression\nClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are examples of regression problems\n\n\nPredicting the price of a house based on features such as number of bedrooms and the year built.\n\n\nPredicting if a house will sell or not based on features like the price of the house, number of rooms, etc.\n\n\nPredicting percentage grade in CPSC 330 based on past grades.\n\n\nPredicting whether you should bicycle tomorrow or not based on the weather forecast.\n\n\nPredicting appropriate thermostat temperature based on the wind speed and the number of people in a room."
  },
  {
    "objectID": "slides-02.html#ml-framework-in-cpsc-330",
    "href": "slides-02.html#ml-framework-in-cpsc-330",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "ML Framework in CPSC 330",
    "text": "ML Framework in CPSC 330\n\nThere are many frameworks to do do machine learning.\nWe’ll mainly be using scikit-learn framework."
  },
  {
    "objectID": "slides-02.html#running-example",
    "href": "slides-02.html#running-example",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Running example",
    "text": "Running example\nImagine you’re in the fortunate situation where, after graduating, you have a few job offers and need to decide which one to choose. You want to pick the job that will likely make you the happiest. To help with your decision, you collect data from like-minded people. Here are the first few rows of this toy dataset.\n\ntoy_happiness_df = pd.read_csv(DATA_DIR + 'toy_job_happiness.csv')\ntoy_happiness_df\n\n\n\n\n\n\n\n\nsupportive_colleagues\nsalary\nfree_coffee\nboss_vegan\nhappy?\n\n\n\n\n0\n0\n70000\n0\n1\nUnhappy\n\n\n1\n1\n60000\n0\n0\nUnhappy\n\n\n2\n1\n80000\n1\n0\nHappy\n\n\n3\n1\n110000\n0\n1\nHappy\n\n\n4\n1\n120000\n1\n0\nHappy\n\n\n5\n1\n150000\n1\n1\nHappy\n\n\n6\n0\n150000\n1\n0\nUnhappy"
  },
  {
    "objectID": "slides-02.html#features-target-example",
    "href": "slides-02.html#features-target-example",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Features, target, example",
    "text": "Features, target, example\n\nWhat are the features \\(X\\)?\n\nfeatures = inputs = predictors = explanatory variables = regressors = independent variables = covariates\n\nWhat’s the target \\(y\\)?\n\ntarget = output = outcome = response variable = dependent variable = labels\n\nCan you think of other relevant features for this problem?\nWhat is an example?"
  },
  {
    "objectID": "slides-02.html#classification-vs.-regression",
    "href": "slides-02.html#classification-vs.-regression",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Classification vs. Regression",
    "text": "Classification vs. Regression\n\nIs this a classification problem or a regression problem?\n\n\n\n\n\n\n\n\n\n\nsupportive_colleagues\nsalary\nfree_coffee\nboss_vegan\nhappy?\n\n\n\n\n0\n0\n70000\n0\n1\nUnhappy\n\n\n1\n1\n60000\n0\n0\nUnhappy\n\n\n2\n1\n80000\n1\n0\nHappy\n\n\n3\n1\n110000\n0\n1\nHappy\n\n\n4\n1\n120000\n1\n0\nHappy\n\n\n5\n1\n150000\n1\n1\nHappy\n\n\n6\n0\n150000\n1\n0\nUnhappy"
  },
  {
    "objectID": "slides-02.html#prediction-vs.-inference",
    "href": "slides-02.html#prediction-vs.-inference",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Prediction vs. Inference",
    "text": "Prediction vs. Inference\n\nInference is using the model to understand the relationship between the features and the target\n\nWhy certain factors influence happiness?\n\nPrediction is using the model to predict the target value for new examples based on learned patterns.\nOf course these goals are related, and in many situations we need both."
  },
  {
    "objectID": "slides-02.html#training",
    "href": "slides-02.html#training",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Training",
    "text": "Training\n\nIn supervised ML, the goal is to learn a function that maps input features (\\(X\\)) to a target (\\(y\\)).\nThe relationship between \\(X\\) and \\(y\\) is often complex, making it difficult to define mathematically.\nWe use algorithms to approximate this complex relationship between \\(X\\) and \\(y\\).\nTraining is the process of applying an algorithm to learn the best function (or model) that maps \\(X\\) to \\(y\\).\nIn this course, I’ll help you develop an intuition for how these models work and demonstrate how to use them in a machine learning pipeline."
  },
  {
    "objectID": "slides-02.html#separating-x-and-y",
    "href": "slides-02.html#separating-x-and-y",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Separating \\(X\\) and \\(y\\)",
    "text": "Separating \\(X\\) and \\(y\\)\n\nIn order to train a model we need to separate \\(X\\) and \\(y\\) from the dataframe.\n\n\nX = toy_happiness_df.drop(columns=[\"happy?\"]) # Extract the feature set by removing the target column \"happy?\"\ny = toy_happiness_df[\"happy?\"] # Extract the target variable \"happy?\""
  },
  {
    "objectID": "slides-02.html#baseline",
    "href": "slides-02.html#baseline",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Baseline",
    "text": "Baseline\n\nLet’s try a simplest algorithm of predicting the most popular target!\n\n\nfrom sklearn.dummy import DummyClassifier\n# Initialize the DummyClassifier to always predict the most frequent class\nmodel = DummyClassifier(strategy=\"most_frequent\")\n# Train the model on the feature set X and target variable y\nmodel.fit(X, y)\n# Add the predicted values as a new column in the dataframe\ntoy_happiness_df['dummy_predictions'] = model.predict(X)\n# Show the dataframe\ntoy_happiness_df\n\n\n\n\n\n\n\n\nsupportive_colleagues\nsalary\nfree_coffee\nboss_vegan\nhappy?\ndummy_predictions\n\n\n\n\n0\n0\n70000\n0\n1\nUnhappy\nHappy\n\n\n1\n1\n60000\n0\n0\nUnhappy\nHappy\n\n\n2\n1\n80000\n1\n0\nHappy\nHappy\n\n\n3\n1\n110000\n0\n1\nHappy\nHappy\n\n\n4\n1\n120000\n1\n0\nHappy\nHappy\n\n\n5\n1\n150000\n1\n1\nHappy\nHappy\n\n\n6\n0\n150000\n1\n0\nUnhappy\nHappy"
  },
  {
    "objectID": "slides-02.html#break",
    "href": "slides-02.html#break",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Break",
    "text": "Break\nLet’s take a break!"
  },
  {
    "objectID": "slides-02.html#activity-20-questions",
    "href": "slides-02.html#activity-20-questions",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Activity: 20 Questions",
    "text": "Activity: 20 Questions\nLet’s play 20 questions! You can ask me up to 20 Yes/No questions to figure out the answer.  \nI’m thinking of a person - who is it ?"
  },
  {
    "objectID": "slides-02.html#intuition",
    "href": "slides-02.html#intuition",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Intuition",
    "text": "Intuition\n\nDecision trees find the “best” way to split data to make predictions.\nEach split is based on a question, like ‘Are the colleagues supportive?’\nThe goal is to group data by similar outcomes at each step.\nNow, let’s see a decision tree using sklearn."
  },
  {
    "objectID": "slides-02.html#decision-tree-with-sklearn",
    "href": "slides-02.html#decision-tree-with-sklearn",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Decision tree with sklearn",
    "text": "Decision tree with sklearn\nLet’s train a simple decision tree on our toy dataset.\n\nfrom sklearn.tree import DecisionTreeClassifier # import the classifier\nfrom sklearn.tree import plot_tree\n\nmodel = DecisionTreeClassifier(max_depth=2, random_state=1) # Create a class object\nmodel.fit(X, y)\nplot_tree(model, filled=True, feature_names = X.columns, class_names=[\"Happy\", \"Unhappy\"], \n          impurity = False, fontsize=12);"
  },
  {
    "objectID": "slides-02.html#prediction",
    "href": "slides-02.html#prediction",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Prediction",
    "text": "Prediction\n\nGiven a new example, how does a decision tree predict the class of this example?\n\nWhat would be the prediction for the example below using the tree above?\n\nsupportive_colleagues = 1, salary = 60000, coffee_machine = 0, vegan_boss = 1,"
  },
  {
    "objectID": "slides-02.html#prediction-with-sklearn",
    "href": "slides-02.html#prediction-with-sklearn",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Prediction with sklearn",
    "text": "Prediction with sklearn\n\nWhat would be the prediction for the example below using the tree above?\n\nsupportive_colleagues = 1, salary = 60000, coffee_machine = 0, vegan_boss = 1,\n\n\n\ntest_example = [[1, 60000, 0, 1]]\nprint(\"Model prediction: \", model.predict(test_example))\nplot_tree(model, filled=True, feature_names = X.columns, class_names = [\"Happy\", \"Unhappy\"], impurity = False, fontsize=9);\n\nModel prediction:  ['Unhappy']"
  },
  {
    "objectID": "slides-02.html#training-high-level",
    "href": "slides-02.html#training-high-level",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Training (high level)",
    "text": "Training (high level)\n\nHow many possible questions could we ask in this context?\n\n\n\n\n\n\n\n\n\n\nsupportive_colleagues\nsalary\nfree_coffee\nboss_vegan\n\n\n\n\n0\n0\n70000\n0\n1\n\n\n1\n1\n60000\n0\n0\n\n\n2\n1\n80000\n1\n0\n\n\n3\n1\n110000\n0\n1\n\n\n4\n1\n120000\n1\n0\n\n\n5\n1\n150000\n1\n1\n\n\n6\n0\n150000\n1\n0"
  },
  {
    "objectID": "slides-02.html#training-high-level-1",
    "href": "slides-02.html#training-high-level-1",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Training (high level)",
    "text": "Training (high level)\n\nDecision tree learning is a search process to find the “best” tree among many possible ones.\nWe evaluate questions using measures like information gain or the Gini index to find the most effective split.\nAt each step, we aim to split the data into groups with more certainty in their outcomes."
  },
  {
    "objectID": "slides-02.html#parameters-vs.-hyperparameters",
    "href": "slides-02.html#parameters-vs.-hyperparameters",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Parameters vs. Hyperparameters",
    "text": "Parameters vs. Hyperparameters\n\nParameters\n\nThe questions (features and thresholds) used to split the data at each node.\nExample: salary &lt;= 75000 at the root node\n\n\nHyperparameters\n\nSettings that control tree growth, like max_depth, which limits how deep the tree can go."
  },
  {
    "objectID": "slides-02.html#decision-boundary-with-max_depth1",
    "href": "slides-02.html#decision-boundary-with-max_depth1",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Decision boundary with max_depth=1",
    "text": "Decision boundary with max_depth=1"
  },
  {
    "objectID": "slides-02.html#decision-boundary-with-max_depth2",
    "href": "slides-02.html#decision-boundary-with-max_depth2",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Decision boundary with max_depth=2",
    "text": "Decision boundary with max_depth=2"
  },
  {
    "objectID": "slides-02.html#iclicker-2.5-baselines-and-decision-trees",
    "href": "slides-02.html#iclicker-2.5-baselines-and-decision-trees",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "iClicker 2.5: Baselines and Decision trees",
    "text": "iClicker 2.5: Baselines and Decision trees\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nChange in features (i.e., binarizing features above) would change DummyClassifier predictions.\n\n\npredict takes only X as argument whereas fit and score take both X and y as arguments.\n\n\nFor the decision tree algorithm to work, the feature values must be binary.\n\n\nThe prediction in a decision tree works by routing the example from the root to the leaf."
  },
  {
    "objectID": "slides-02.html#break-1",
    "href": "slides-02.html#break-1",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Break",
    "text": "Break\nLet’s take a break!"
  },
  {
    "objectID": "slides-02.html#group-work-class-demo-live-coding",
    "href": "slides-02.html#group-work-class-demo-live-coding",
    "title": "Lecture 2: Terminology, Baselines, Decision Trees",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nIn some of the classes, we will do a bit of live coding to get your used to practical machine learning. You are highly encouraged to follow along - we won’t usually finish everything in the demo, but it should be a significant portion that you can finish off after class.\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-18.html#announcements",
    "href": "slides-18.html#announcements",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Announcements",
    "text": "Announcements\n\nHW7 was due yesterday\nHW8 has been released (due next week Monday)\n\nAlmost there! Hang in there 😊\n\nMidterm 2 grading is in progress."
  },
  {
    "objectID": "slides-18.html#iclicker-18.1",
    "href": "slides-18.html#iclicker-18.1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "iClicker 18.1",
    "text": "iClicker 18.1\niClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nIt’s possible to use word2vec embedding representations for text classification instead of bag-of-words representation.\n\n\nThe topic model approach we used in the last lecture, Latent Dirichlet Allocation (LDA), is an unsupervised approach.\n\n\nIn an LDA topic model, the same word can be associated with two different topics with high probability.\n\n\nIn an LDA topic model, a document is a mixture of multiple topics.\n\n\nIf I train a topic model on a large collection of news articles with K = 10, I would get 10 topic labels (e.g., sports, culture, politics, finance) as output."
  },
  {
    "objectID": "slides-18.html#multiclass-classification",
    "href": "slides-18.html#multiclass-classification",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Multiclass classification",
    "text": "Multiclass classification\n\nSo far we have been talking about binary classification\nCan we use these classifiers when there are more than two classes?\n\n“ImageNet” computer vision competition, for example, has 1000 classes\n\nCan we use decision trees or KNNs for multi-class classification?\nWhat about logistic regression?"
  },
  {
    "objectID": "slides-18.html#softmax-function-for-probabilities",
    "href": "slides-18.html#softmax-function-for-probabilities",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Softmax Function for Probabilities",
    "text": "Softmax Function for Probabilities\nGiven an input, the probability that it belongs to class \\(j \\in \\{1, 2, \\dots, K\\}\\) is calculated using the softmax function:\n\\(P(y = j \\mid x_i) = \\frac{e^{w_j^\\top x_i + b_j}}{\\sum_{k=1}^{K} e^{w_k^\\top x_i + b_k}}\\)\n\n\\(x_i\\) is the \\(i^{th}\\) example\n\\(w_j\\) is the weight vector for class \\(j\\).\n\\(b_j\\) is the bias term for class \\(j\\).\n\\(K\\) is the total number of classes."
  },
  {
    "objectID": "slides-18.html#making-predictions",
    "href": "slides-18.html#making-predictions",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Making Predictions",
    "text": "Making Predictions\n\nCompute Probabilities:\nFor each class \\(j\\), compute the probability \\(P(y = j \\mid x_i)\\) using the softmax function.\nSelect the Class with the Highest Probability:\nThe predicted class () is:\n\\(\\hat{y} = \\arg \\max_{j \\in \\{1, \\dots, K\\}} P(y = j \\mid x_i)\\)"
  },
  {
    "objectID": "slides-18.html#binary-vs-multinomial-logistic-regression",
    "href": "slides-18.html#binary-vs-multinomial-logistic-regression",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Binary vs multinomial logistic regression",
    "text": "Binary vs multinomial logistic regression\n\n\n\n\n\n\n\n\nAspect\nBinary Logistic Regression\nMultinomial Logistic Regression\n\n\n\n\nTarget variable\n2 classes (binary)\nMore than 2 classes (multi-class)\n\n\nGetting probabilities\nSigmoid\nSoftmax\n\n\nparameters\n\\(d\\) weights, one per feature and the bias term\n\\(d\\) weights and a bias term per class\n\n\nOutput\nSingle probability\nProbability distribution over classes\n\n\nUse case\nBinary classification (e.g., spam detection)\nMulti-class classification (e.g., image classification)"
  },
  {
    "objectID": "slides-18.html#image-classification",
    "href": "slides-18.html#image-classification",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Image classification",
    "text": "Image classification\n\n\nHave you used search in Google Photos? You can search for “my photos of cat” and it will retrieve photos from your libraries containing cats. This can be done using image classification, which is treated as a supervised learning problem, where we define a set of target classes (objects to identify in images), and train a model to recognize them using labeled example photos."
  },
  {
    "objectID": "slides-18.html#image-classification-1",
    "href": "slides-18.html#image-classification-1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Image classification",
    "text": "Image classification\n\n\nImage classification is not an easy problem because of the variations in the location of the object, lighting, background, camera angle, camera focus etc."
  },
  {
    "objectID": "slides-18.html#neural-networks",
    "href": "slides-18.html#neural-networks",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Neural networks",
    "text": "Neural networks\n\n\n\nNeural networks are perfect for these types of problems where local structures are important.\nA significant advancement in image classification was the application of convolutional neural networks (ConvNets or CNNs) to this problem.\n\nImageNet Classification with Deep Convolutional Neural Networks\nAchieved a winning test error rate of 15.3%, compared to 26.2% achieved by the second-best entry in the ILSVRC-2012 competition.\n\nLet’s go over the basics of a neural network."
  },
  {
    "objectID": "slides-18.html#introduction-to-neural-networks",
    "href": "slides-18.html#introduction-to-neural-networks",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Introduction to neural networks",
    "text": "Introduction to neural networks\n\n\n\nNeural networks can be viewed a generalization of linear models where we apply a series of transformations.\nHere is graphical representation of a logistic regression model.\nWe have 4 features: x[0], x[1], x[2], x[3]"
  },
  {
    "objectID": "slides-18.html#adding-a-layer-of-transformations",
    "href": "slides-18.html#adding-a-layer-of-transformations",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Adding a layer of transformations",
    "text": "Adding a layer of transformations\n\n\n\nBelow we are adding one “layer” of transformations in between features and the target.\nWe are repeating the the process of computing the weighted sum multiple times.\n\nThe hidden units (e.g., h[1], h[2], …) represent the intermediate processing steps."
  },
  {
    "objectID": "slides-18.html#one-more-layer-of-transformations",
    "href": "slides-18.html#one-more-layer-of-transformations",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "One more layer of transformations",
    "text": "One more layer of transformations\n\n\n\nNow we are adding one more layer of transformations."
  },
  {
    "objectID": "slides-18.html#neural-networks-1",
    "href": "slides-18.html#neural-networks-1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Neural networks",
    "text": "Neural networks\n\n\n\nWith a neural net, you specify the number of features after each transformation.\n\nIn the above, it goes from 4 to 3 to 3 to 1.\n\nTo make them really powerful compared to the linear models, we apply a non-linear function to the weighted sum for each hidden node.\nNeural network = neural net\nDeep learning ~ using neural networks"
  },
  {
    "objectID": "slides-18.html#why-neural-networks",
    "href": "slides-18.html#why-neural-networks",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Why neural networks?",
    "text": "Why neural networks?\n\n\n\nThey can learn very complex functions.\n\nThe fundamental tradeoff is primarily controlled by the number of layers and layer sizes.\nMore layers / bigger layers –&gt; more complex model.\nYou can generally get a model that will not underfit.\n\nThey work really well for structured data:\n\n1D sequence, e.g. timeseries, language\n2D image\n3D image or video\n\nThey’ve had some incredible successes in the last 12 years.\nTransfer learning (coming later today) is really useful."
  },
  {
    "objectID": "slides-18.html#why-not-neural-networks",
    "href": "slides-18.html#why-not-neural-networks",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Why not neural networks?",
    "text": "Why not neural networks?\n\n\n\nOften they require a lot of data.\nThey require a lot of compute time, and, to be faster, specialized hardware called GPUs.\nThey have huge numbers of hyperparameters\n\nThink of each layer having hyperparameters, plus some overall hyperparameters.\nBeing slow compounds this problem.\n\nThey are not interpretable.\nI don’t recommend training them on your own without further training\nGood news\n\nYou don’t have to train your models from scratch in order to use them.\nI’ll show you some ways to use neural networks without training them yourselves."
  },
  {
    "objectID": "slides-18.html#deep-learning-software",
    "href": "slides-18.html#deep-learning-software",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Deep learning software",
    "text": "Deep learning software\n\n\nThe current big players are:\n\nPyTorch\nTensorFlow\n\nBoth are heavily used in industry. If interested, see comparison of deep learning software."
  },
  {
    "objectID": "slides-18.html#introduction-to-computer-vision",
    "href": "slides-18.html#introduction-to-computer-vision",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Introduction to computer vision",
    "text": "Introduction to computer vision\n\n\n\nComputer vision refers to understanding images/videos, usually using ML/AI.\nIn the last decade this field has been dominated by deep learning. We will explore image classification and object detection."
  },
  {
    "objectID": "slides-18.html#introduction-to-computer-vision-1",
    "href": "slides-18.html#introduction-to-computer-vision-1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Introduction to computer vision",
    "text": "Introduction to computer vision\n\n\n\nimage classification: is this a cat or a dog?\nobject localization: where is the cat in this image?\nobject detection: What are the various objects in the image?\ninstance segmentation: What are the shapes of these various objects in the image?\nand much more…"
  },
  {
    "objectID": "slides-18.html#pre-trained-models",
    "href": "slides-18.html#pre-trained-models",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models",
    "text": "Pre-trained models\n\n\n\nIn practice, very few people train an entire CNN from scratch because it requires a large dataset, powerful computers, and a huge amount of human effort to train the model.\nInstead, a common practice is to download a pre-trained model and fine tune it for your task. This is called transfer learning.\nTransfer learning is one of the most common techniques used in the context of computer vision and natural language processing.\nIt refers to using a model already trained on one task as a starting point for learning to perform another task."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box",
    "href": "slides-18.html#pre-trained-models-out-of-the-box",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\n\n\n\n\nLet’s first apply one of these pre-trained models to our own problem right out of the box."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box-1",
    "href": "slides-18.html#pre-trained-models-out-of-the-box-1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\n\n\nWe can easily download famous models using the torchvision.models module. All models are available with pre-trained weights (based on ImageNet’s 224 x 224 images)\nWe used a pre-trained model vgg16 which is trained on the ImageNet data.\nWe preprocess the given image.\nWe get prediction from this pre-trained model on a given image along with prediction probabilities.\n\nFor a given image, this model will spit out one of the 1000 classes from ImageNet."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box-2",
    "href": "slides-18.html#pre-trained-models-out-of-the-box-2",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\nLet’s predict labels with associated probabilities for unseen images\n\n\n\n\n\n\n\n\n\n\n\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/runner/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n\n\n                                     Class  Probability score\n         cheetah, chetah, Acinonyx jubatus              0.983\n                  leopard, Panthera pardus              0.012\njaguar, panther, Panthera onca, Felis onca              0.004\n       snow leopard, ounce, Panthera uncia              0.001\n--------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n                        Class  Probability score\nWalker hound, Walker foxhound              0.580\n             English foxhound              0.091\n                  EntleBucher              0.080\n                       beagle              0.065\n--------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n                                   Class  Probability score\n                                 macaque              0.714\npatas, hussar monkey, Erythrocebus patas              0.122\n      proboscis monkey, Nasalis larvatus              0.098\n                   guenon, guenon monkey              0.017\n--------------------------------------------------------------\n\n\n\n\n\n\n\n\n\n                         Class  Probability score\n                     tiger cat              0.353\n              tabby, tabby cat              0.207\n               lynx, catamount              0.050\nPembroke, Pembroke Welsh corgi              0.046\n--------------------------------------------------------------"
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box-3",
    "href": "slides-18.html#pre-trained-models-out-of-the-box-3",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\n\n\nWe got these predictions without “doing the ML ourselves”.\nWe are using pre-trained vgg16 model which is available in torchvision.\n\ntorchvision has many such pre-trained models available that have been very successful across a wide range of tasks: AlexNet, VGG, ResNet, Inception, MobileNet, etc.\n\nMany of these models have been pre-trained on famous datasets like ImageNet.\nSo if we use them out-of-the-box, they will give us one of the ImageNet classes as classification."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box-4",
    "href": "slides-18.html#pre-trained-models-out-of-the-box-4",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\n\n\nLet’s try some images which are unlikely to be there in ImageNet.\nIt’s not doing very well here because ImageNet doesn’t have proper classes for these images."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-out-of-the-box-5",
    "href": "slides-18.html#pre-trained-models-out-of-the-box-5",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models out-of-the-box",
    "text": "Pre-trained models out-of-the-box\n\n\n\nHere we are Pre-trained models out-of-the-box.\nCan we use pre-trained models for our own classification problem with our classes?\nYes!! We have two options here:\n\nAdd some extra layers to the pre-trained network to suit our particular task\nPass training data through the network and save the output to use as features for training some other model"
  },
  {
    "objectID": "slides-18.html#pre-trained-models-to-extract-features",
    "href": "slides-18.html#pre-trained-models-to-extract-features",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models to extract features",
    "text": "Pre-trained models to extract features\n\n\n\nLet’s use pre-trained models to extract features.\nWe will pass our specific data through a pre-trained network to get a feature vector for each example in the data.\nThe feature vector is usually extracted from the last layer, before the classification layer from the pre-trained network.\nYou can think of each layer a transformer applying some transformations on the input received to that later."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-to-extract-features-1",
    "href": "slides-18.html#pre-trained-models-to-extract-features-1",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models to extract features",
    "text": "Pre-trained models to extract features\n\n\n\nOnce we extract these feature vectors for all images in our training data, we can train a machine learning classifier such as logistic regression or random forest.\nThis classifier will be trained on our classes using feature representations extracted from the pre-trained models.\n\nLet’s try this out.\nIt’s better to train such models with GPU. Since our dataset is quite small, we won’t have problems running it on a CPU."
  },
  {
    "objectID": "slides-18.html#pre-trained-models-to-extract-features-2",
    "href": "slides-18.html#pre-trained-models-to-extract-features-2",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models to extract features",
    "text": "Pre-trained models to extract features\n\n\nLet’s look at some sample images in the dataset."
  },
  {
    "objectID": "slides-18.html#dataset-statistics",
    "href": "slides-18.html#dataset-statistics",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Dataset statistics",
    "text": "Dataset statistics\n\n\nHere is the stat of our toy dataset.\n\n\nClasses: ['beet_salad', 'chocolate_cake', 'edamame', 'french_fries', 'pizza', 'spring_rolls', 'sushi']\nClass count: 40, 38, 40\nSamples: 283\nFirst sample: ('data/food/train/beet_salad/104294.jpg', 0)"
  },
  {
    "objectID": "slides-18.html#pre-trained-models-to-extract-features-3",
    "href": "slides-18.html#pre-trained-models-to-extract-features-3",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Pre-trained models to extract features",
    "text": "Pre-trained models to extract features\n\n\n\nNow for each image in our dataset, we’ll extract a feature vector from a pre-trained model called densenet121, which is trained on the ImageNet dataset.\n\n\n\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/runner/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth"
  },
  {
    "objectID": "slides-18.html#shape-of-the-feature-vector",
    "href": "slides-18.html#shape-of-the-feature-vector",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Shape of the feature vector",
    "text": "Shape of the feature vector\n\n\n\nNow we have extracted feature vectors for all examples. What’s the shape of these features?\n\n\n\ntorch.Size([283, 1024])\n\n\n\nThe size of each feature vector is 1024 because the size of the last layer in densenet architecture is 1024.\n\n\nSource"
  },
  {
    "objectID": "slides-18.html#a-feature-vector-given-by-densenet",
    "href": "slides-18.html#a-feature-vector-given-by-densenet",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "A feature vector given by densenet",
    "text": "A feature vector given by densenet\n \n\nLet’s examine the feature vectors.\n\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n1014\n1015\n1016\n1017\n1018\n1019\n1020\n1021\n1022\n1023\n\n\n\n\n0\n0.000594\n0.005223\n0.002873\n0.001198\n0.095008\n0.586996\n0.000433\n0.003686\n0.270852\n0.000384\n...\n0.690704\n0.614862\n0.795965\n1.646564\n2.446819\n1.365812\n0.528616\n0.365612\n0.255720\n0.183180\n\n\n1\n0.000409\n0.002568\n0.005813\n0.000984\n0.144840\n0.398514\n0.000489\n0.004420\n0.114888\n0.000214\n...\n1.000378\n0.340965\n0.381936\n1.984859\n2.476552\n3.327962\n0.019797\n2.603055\n0.007626\n0.605141\n\n\n2\n0.000416\n0.001159\n0.003767\n0.003172\n0.108386\n0.586645\n0.000397\n0.005292\n0.402601\n0.000431\n...\n0.039040\n0.393661\n0.009340\n0.441225\n0.091899\n0.169581\n0.298865\n1.187944\n0.038597\n1.138483\n\n\n3\n0.000497\n0.005999\n0.002178\n0.002357\n0.148310\n0.246634\n0.001014\n0.002068\n0.051969\n0.000257\n...\n2.246375\n3.856320\n1.375525\n0.013484\n0.142043\n0.458633\n0.615500\n0.938255\n0.201702\n2.921425\n\n\n4\n0.000736\n0.004440\n0.005242\n0.002650\n0.117544\n0.587100\n0.000218\n0.003063\n0.109905\n0.000228\n...\n0.918649\n0.139182\n3.108648\n5.024370\n0.008162\n0.118332\n0.100525\n1.571189\n0.676852\n0.192658\n\n\n\n\n5 rows × 1024 columns\n\n\n\n\nThe features are hard to interpret but they have some important information about the images which can be useful for classification."
  },
  {
    "objectID": "slides-18.html#logistic-regression-with-the-extracted-features",
    "href": "slides-18.html#logistic-regression-with-the-extracted-features",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Logistic regression with the extracted features",
    "text": "Logistic regression with the extracted features\n\n\n\nLet’s try out logistic regression on these extracted features.\n\n\n\nTraining score:  1.0\n\n\n\n\nValidation score:  0.8208955223880597\n\n\n\nThis is great accuracy for so little data and little effort!!!"
  },
  {
    "objectID": "slides-18.html#sample-predictions",
    "href": "slides-18.html#sample-predictions",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Sample predictions",
    "text": "Sample predictions\n\n\nLet’s examine some sample predictions on the validation set."
  },
  {
    "objectID": "slides-18.html#object-detection",
    "href": "slides-18.html#object-detection",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Object detection",
    "text": "Object detection\n\n\n\nAnother useful task and tool to know is object detection using YOLO model.\nLet’s identify objects in a sample image using a pretrained model called YOLO8.\nList the objects present in this image."
  },
  {
    "objectID": "slides-18.html#object-detection-using-yolo",
    "href": "slides-18.html#object-detection-using-yolo",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Object detection using YOLO",
    "text": "Object detection using YOLO\n\n\nLet’s try this out using a pre-trained model.\n\nfrom ultralytics import YOLO\nmodel = YOLO(\"yolov8n.pt\")  # pretrained YOLOv8n model\n\nyolo_input = \"data/yolo_test/3356700488_183566145b.jpg\"\nyolo_result = \"data/yolo_result.jpg\"\n# Run batched inference on a list of images\nresult = model(yolo_input)  # return a list of Results objects\nresult[0].save(filename=yolo_result)\n\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/home/runner/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\nimage 1/1 /home/runner/work/cpsc330-slides/cpsc330-slides/website/data/yolo_test/3356700488_183566145b.jpg: 512x640 4 persons, 2 cars, 1 stop sign, 92.5ms\nSpeed: 1.4ms preprocess, 92.5ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n\n\n'data/yolo_result.jpg'"
  },
  {
    "objectID": "slides-18.html#object-detection-output",
    "href": "slides-18.html#object-detection-output",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Object detection output",
    "text": "Object detection output"
  },
  {
    "objectID": "slides-18.html#summary",
    "href": "slides-18.html#summary",
    "title": "CPSC 330 Lecture 18: Introduction to deep learning and computer vision",
    "section": "Summary",
    "text": "Summary\n\n\n\nNeural networks are a flexible class of models.\n\nThey are particular powerful for structured input like images, videos, audio, etc.\nThey can be challenging to train and often require significant computational resources.\n\nThe good news is we can use pre-trained neural networks.\n\nThis saves us a huge amount of time/cost/effort/resources.\nWe can use these pre-trained networks directly or use them as feature transformers."
  },
  {
    "objectID": "slides-11.html#ensembles",
    "href": "slides-11.html#ensembles",
    "title": "CPSC 330 Lecture 11: Ensembles",
    "section": "Ensembles",
    "text": "Ensembles\nToday, we will do a class of live coding and going through the Jupyter Notebook to get back into the swing of things."
  },
  {
    "objectID": "slides-11.html#group-work-class-demo-live-coding-if-time-permits",
    "href": "slides-11.html#group-work-class-demo-live-coding-if-time-permits",
    "title": "CPSC 330 Lecture 11: Ensembles",
    "section": "Group Work: Class Demo & Live Coding (if time permits)",
    "text": "Group Work: Class Demo & Live Coding (if time permits)\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-15.html#super-cool-demo",
    "href": "slides-15.html#super-cool-demo",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Super cool Demo!",
    "text": "Super cool Demo!\nYou can download and checkout the Demo here.\nAll credit to Dr. Varada Kolhatkar for putting this together!"
  },
  {
    "objectID": "slides-15.html#recap-iclicker-exercise-15.3",
    "href": "slides-15.html#recap-iclicker-exercise-15.3",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Recap: iClicker Exercise 15.3",
    "text": "Recap: iClicker Exercise 15.3\nSelect all of the following statements which are True\n\n\nIf you train K-Means with n_clusters= the number of examples, the inertia value will be 0.\n\n\nThe elbow plot shows the tradeoff between within cluster distance and the number of clusters.\n\n\nUnlike the Elbow method, the Silhouette method is not dependent on the notion of cluster centers.\n\n\nThe elbow plot is not a reliable method to obtain the optimal number of clusters in all cases.\n\n\nThe Silhouette scores ranges between -1 and 1 where higher scores indicates better cluster assignments."
  },
  {
    "objectID": "slides-15.html#iclicker-exercise-16.1",
    "href": "slides-15.html#iclicker-exercise-16.1",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "iClicker Exercise 16.1",
    "text": "iClicker Exercise 16.1\nSelect all of the following statements which are TRUE.\n\n\nSimilar to K-nearest neighbours, K-Means is a non parametric model.\n\n\nThe meaning of K in K-nearest neighbours and K-Means clustering is very similar.\n\n\nScaling of input features is crucial in clustering.\n\n\n\nIn clustering, it’s almost always a good idea to find equal-sized clusters."
  },
  {
    "objectID": "slides-15.html#shape-of-clusters",
    "href": "slides-15.html#shape-of-clusters",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Shape of clusters",
    "text": "Shape of clusters\n\nGood for spherical clusters of more or less equal sizes"
  },
  {
    "objectID": "slides-15.html#k-means-failure-case-1",
    "href": "slides-15.html#k-means-failure-case-1",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "K-Means: failure case 1",
    "text": "K-Means: failure case 1\n\nK-Means performs poorly if the clusters have more complex shapes (e.g., two moons data below)."
  },
  {
    "objectID": "slides-15.html#k-means-failure-case-2",
    "href": "slides-15.html#k-means-failure-case-2",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "K-Means: failure case 2",
    "text": "K-Means: failure case 2\n\nAgain, K-Means is unable to capture complex cluster shapes."
  },
  {
    "objectID": "slides-15.html#k-means-failure-case-3",
    "href": "slides-15.html#k-means-failure-case-3",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "K-Means: failure case 3",
    "text": "K-Means: failure case 3\n\nIt assumes that all directions are equally important for each cluster and fails to identify non-spherical clusters."
  },
  {
    "objectID": "slides-15.html#dbscan-1",
    "href": "slides-15.html#dbscan-1",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "DBSCAN",
    "text": "DBSCAN\n\nX, y = make_moons(n_samples=200, noise=0.08, random_state=42)\ndbscan = DBSCAN(eps=0.2)\ndbscan.fit(X)\nplot_original_clustered(X, dbscan, dbscan.labels_)"
  },
  {
    "objectID": "slides-15.html#how-does-it-work",
    "href": "slides-15.html#how-does-it-work",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "How does it work?",
    "text": "How does it work?"
  },
  {
    "objectID": "slides-15.html#dbscan-analogy",
    "href": "slides-15.html#dbscan-analogy",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "DBSCAN Analogy",
    "text": "DBSCAN Analogy\nConsider DBSCAN in a social context:\n\nSocial butterflies (🦋): Core points\nFriends of social butterflies who are not social butterflies: Border points\nLone wolves (🐺): Noise points"
  },
  {
    "objectID": "slides-15.html#two-main-hyperparameters",
    "href": "slides-15.html#two-main-hyperparameters",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Two main hyperparameters",
    "text": "Two main hyperparameters\n\neps: determines what it means for points to be “close”\nmin_samples: determines the number of neighboring points we require to consider in order for a point to be part of a cluster"
  },
  {
    "objectID": "slides-15.html#dbscan-failure-cases",
    "href": "slides-15.html#dbscan-failure-cases",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "DBSCAN: failure cases",
    "text": "DBSCAN: failure cases\n\nLet’s consider this dataset with three clusters of varying densities.\n\nK-Means performs better compared to DBSCAN. But it has the benefit of knowing the value of K in advance.\n\n\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]"
  },
  {
    "objectID": "slides-15.html#break",
    "href": "slides-15.html#break",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Break",
    "text": "Break\nLet’s take a 10-min break!"
  },
  {
    "objectID": "slides-15.html#dendrogram",
    "href": "slides-15.html#dendrogram",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Dendrogram",
    "text": "Dendrogram\nDefinition: visual representation of a tree, in particular, the hierarchical representation of data…\n\nSource"
  },
  {
    "objectID": "slides-15.html#example-languages",
    "href": "slides-15.html#example-languages",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Example: Languages",
    "text": "Example: Languages\n\nSource"
  },
  {
    "objectID": "slides-15.html#hierarchical-clustering",
    "href": "slides-15.html#hierarchical-clustering",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Hierarchical clustering",
    "text": "Hierarchical clustering"
  },
  {
    "objectID": "slides-15.html#flat-clusters",
    "href": "slides-15.html#flat-clusters",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Flat clusters",
    "text": "Flat clusters\n\nThis is good but how can we get cluster labels from a dendrogram?\nWe can bring the clustering to a “flat” format use fcluster"
  },
  {
    "objectID": "slides-15.html#linkage-criteria",
    "href": "slides-15.html#linkage-criteria",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Linkage criteria",
    "text": "Linkage criteria\n\nWhen we create a dendrogram, we need to calculate distance between clusters. How do we measure distances between clusters?\nThe linkage criteria determines how to find similarity between clusters:\nSome example linkage criteria are:\n\nSingle linkage → smallest minimal distance, leads to loose clusters\nComplete linkage → smallest maximum distance, leads to tight clusters\nAverage linkage → smallest average distance between all pairs of points in the clusters\nWard linkage → smallest increase in within-cluster variance, leads to equally sized clusters"
  },
  {
    "objectID": "slides-15.html#activity",
    "href": "slides-15.html#activity",
    "title": "CPSC 330 Lecture 15: DBSCAN, Hierarchical Clustering",
    "section": "Activity",
    "text": "Activity\n\nFill in the table below\n\n\n\n\n\n\n\n\n\n\nClustering Method\nKMeans\nDBSCAN\nHierarchical Clustering\n\n\n\n\nApproach\n\n\n\n\n\nHyperparameters\n\n\n\n\n\nShape of clusters\n\n\n\n\n\nHandling noise\n\n\n\n\n\nExamples"
  },
  {
    "objectID": "slides-03.html#announcements",
    "href": "slides-03.html#announcements",
    "title": "Lecture 3: ML fundamentals",
    "section": "Announcements",
    "text": "Announcements\n\nRemember, my office hours are MWF from 1:00 - 1:30 PM in DMP 310 (after class)\nHomework 2 (hw2) was released on Wednesday, it is due May 20, 10:00 pm\n\nYou are welcome to broadly discuss it with your classmates but final answers and submissions must be your own.\nGroup submissions are not allowed for this assignment.\n\nAdvice on keeping up with the material\n\nPractice!\nMake sure you run the lecture notes on your laptop and experiment with the code.\nStart early on homework assignments.\n\nIf you are still on the waitlist, it’s your responsibility to keep up with the material and submit assignments!\nLast day to drop without a W standing is today: May 16, 2025"
  },
  {
    "objectID": "slides-03.html#dropping-lowest-homework-update",
    "href": "slides-03.html#dropping-lowest-homework-update",
    "title": "Lecture 3: ML fundamentals",
    "section": "Dropping lowest homework (Update)",
    "text": "Dropping lowest homework (Update)\n\nCPSC 330 has 9 homework assignments that are all an integral part of your learning\nTo account for illnesses, other commitments, and to preserve your mental health, there has long been a policy of dropping your lowest HW score.\nAfter some analysis from the data from previous terms (Learning Analytics!), there is a slight modification to this policy:\n\n\nWith the exception of HW5, we will drop your lowest homework grade - all students must complete HW5.\n\n\nThis is to encourage all students to complete HW5! It’s important!"
  },
  {
    "objectID": "slides-03.html#recap",
    "href": "slides-03.html#recap",
    "title": "Lecture 3: ML fundamentals",
    "section": "Recap",
    "text": "Recap\n\nImportance of generalization in supervised machine learning\nData splitting as a way to approximate generalization error\nTrain, test, validation, deployment data\nOverfitting, underfitting, the fundamental tradeoff, and the golden rule.\nCross-validation"
  },
  {
    "objectID": "slides-03.html#recap-1",
    "href": "slides-03.html#recap-1",
    "title": "Lecture 3: ML fundamentals",
    "section": "Recap",
    "text": "Recap\nA typical sequence of steps to train supervised machine learning models\n\ntraining the model on the train split\ntuning hyperparamters using the validation split\nchecking the generalization performance on the test split"
  },
  {
    "objectID": "slides-03.html#iclicker-3.1",
    "href": "slides-03.html#iclicker-3.1",
    "title": "Lecture 3: ML fundamentals",
    "section": "iClicker 3.1",
    "text": "iClicker 3.1\nClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\nA decision tree model with no depth (the default max_depth in sklearn) is likely to perform very well on the deployment data.\n\n\nData splitting helps us assess how well our model would generalize.\n\n\nDeployment data is only scored once.\n\n\nValidation data could be used for hyperparameter optimization.\n\n\nIt’s recommended that data be shuffled before splitting it into train and test sets."
  },
  {
    "objectID": "slides-03.html#additional-resource",
    "href": "slides-03.html#additional-resource",
    "title": "Lecture 3: ML fundamentals",
    "section": "Additional Resource",
    "text": "Additional Resource\n\n\n\n        \n        \n\n\nReference: MLU-Explain - Data Splitting"
  },
  {
    "objectID": "slides-03.html#iclicker-3.2",
    "href": "slides-03.html#iclicker-3.2",
    "title": "Lecture 3: ML fundamentals",
    "section": "iClicker 3.2",
    "text": "iClicker 3.2\nClicker cloud join link: https://join.iclicker.com/YJHS\nSelect all of the following statements which are TRUE.\n\n\\(k\\)-fold cross-validation calls fit \\(k\\) times\nWe use cross-validation to get a more robust estimate of model performance.\nIf the mean train accuracy is much higher than the mean cross-validation accuracy it’s likely to be a case of overfitting.\nThe fundamental tradeoff of ML states that as training error goes down, validation error goes up.\nA decision stump on a complicated classification problem is likely to underfit."
  },
  {
    "objectID": "slides-03.html#additional-resource-1",
    "href": "slides-03.html#additional-resource-1",
    "title": "Lecture 3: ML fundamentals",
    "section": "Additional Resource",
    "text": "Additional Resource\n\n\n\n        \n        \n\n\nReference: MLU-Explain - Cross Validation"
  },
  {
    "objectID": "slides-03.html#break",
    "href": "slides-03.html#break",
    "title": "Lecture 3: ML fundamentals",
    "section": "Break",
    "text": "Break\nLet’s take a break!"
  },
  {
    "objectID": "slides-03.html#group-work-class-demo-live-coding",
    "href": "slides-03.html#group-work-class-demo-live-coding",
    "title": "Lecture 3: ML fundamentals",
    "section": "Group Work: Class Demo & Live Coding",
    "text": "Group Work: Class Demo & Live Coding\nFor this demo, each student should click this link to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today."
  },
  {
    "objectID": "slides-midterm1-review.html#announcements",
    "href": "slides-midterm1-review.html#announcements",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Announcements",
    "text": "Announcements\n\nNothing new today!"
  },
  {
    "objectID": "slides-midterm1-review.html#what-is-machine-learning",
    "href": "slides-midterm1-review.html#what-is-machine-learning",
    "title": "CPSC 330: Midterm 1 review",
    "section": "What is machine learning",
    "text": "What is machine learning\n\nML uses data to build models that identify patterns, make predictions, or generate content.\nIt enables computers to learn from data.\nNo single model is suitable for all situations."
  },
  {
    "objectID": "slides-midterm1-review.html#when-is-ml-suitable",
    "href": "slides-midterm1-review.html#when-is-ml-suitable",
    "title": "CPSC 330: Midterm 1 review",
    "section": "When is ML suitable?",
    "text": "When is ML suitable?\n\nML excels when the problem involve identifying complex patterns or relationships in large datasets that are difficult for humans to discern manually.\nRule-based systems are suitable where clear and deterministic rules can be defined. Good for structured decision making.\nHuman experts are good with problems which require deep contextual understanding, ethical judgment, creative input, or emotional intelligence."
  },
  {
    "objectID": "slides-midterm1-review.html#terminology",
    "href": "slides-midterm1-review.html#terminology",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Terminology",
    "text": "Terminology\n\nFeatures (X) and target (y)\nExamples\nPredictions\nAccuracy, error\nParameters and hyperparameters\nDecision boundaries"
  },
  {
    "objectID": "slides-midterm1-review.html#important-concepts",
    "href": "slides-midterm1-review.html#important-concepts",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Important concepts",
    "text": "Important concepts\n\nWhy do we split the data? What are train/valid/test splits?\nWhat are the benefits of cross-validation?\nWhat is underfitting and overfitting?\nWhat’s the fundamental trade-off in supervised machine learning?\nWhat is the golden rule of machine learning?"
  },
  {
    "objectID": "slides-midterm1-review.html#overfitting-and-underfitting",
    "href": "slides-midterm1-review.html#overfitting-and-underfitting",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Overfitting and underfitting",
    "text": "Overfitting and underfitting\n\n\n\nSource\n\n\nAn overfit model matches the training set so closely that it fails to make correct predictions on new unseen data.\n\nAn underfit model is too simple and does not even make good predictions on the training data"
  },
  {
    "objectID": "slides-midterm1-review.html#the-fundamental-tradeoff",
    "href": "slides-midterm1-review.html#the-fundamental-tradeoff",
    "title": "CPSC 330: Midterm 1 review",
    "section": "The fundamental tradeoff",
    "text": "The fundamental tradeoff\n\n\n\n\n\n\n\n\n\nAs you increase the model complexity, training score tends to go up and the gap between train and validation scores tends to go up.\n\nHow to pick a model?"
  },
  {
    "objectID": "slides-midterm1-review.html#supervised-models-we-have-seen",
    "href": "slides-midterm1-review.html#supervised-models-we-have-seen",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Supervised models we have seen",
    "text": "Supervised models we have seen\n\nDecision trees: Split data into subsets based on feature values to create decision rules\nk-NNs: Classify based on the majority vote from k nearest neighbors\nSVM RBFs: Create a boundary using an RBF kernel to separate classes\nLinear models: Assumption that the relationship between X and y is linear"
  },
  {
    "objectID": "slides-midterm1-review.html#comparison-of-models",
    "href": "slides-midterm1-review.html#comparison-of-models",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Comparison of models",
    "text": "Comparison of models\n\n\n\n\n\n\n\n\n\nModel\nParameters and hyperparameters\nStrengths\nWeaknesses\n\n\n\n\nDecision Trees\n\n\n\n\n\nKNNs\n\n\n\n\n\nSVM RBF\n\n\n\n\n\nLinear models"
  },
  {
    "objectID": "slides-midterm1-review.html#sklearn-transformers",
    "href": "slides-midterm1-review.html#sklearn-transformers",
    "title": "CPSC 330: Midterm 1 review",
    "section": "sklearn Transformers",
    "text": "sklearn Transformers\n\n\n\n\n\n\n\n\nTransformer\nHyperparameters\nWhen to use?\n\n\n\n\nSimpleImputer\n\n\n\n\nStandardScaler\n\n\n\n\nOneHotEncoder\n\n\n\n\nOrdinalEncoder\n\n\n\n\nCountVectorizer\n\n\n\n\nTransformedTargetRegressor"
  },
  {
    "objectID": "slides-midterm1-review.html#features",
    "href": "slides-midterm1-review.html#features",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Features",
    "text": "Features\n\nUsing features that are directly related to the target can cause data leakage.\n\nExample: If you’re building a model to predict the churn rate of customers in a subscription service (churned or not churned) and you are using a feature like “account deactivation date”.\n\n\nIf a feature essentially gives away the answer, the model might perform exceptionally well during training but fail to generalize to new, unseen data."
  },
  {
    "objectID": "slides-midterm1-review.html#preprocessing",
    "href": "slides-midterm1-review.html#preprocessing",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nIncorporating information from the validation or test data during the preprocessing phase (e.g., scaling based on the distribution of the entire dataset instead of just the training set) can also lead to leakage. This can happen if the transformations applied to the training data are influenced by the whole dataset, thus indirectly feeding information about the test set into the model during training."
  },
  {
    "objectID": "slides-midterm1-review.html#pipelines",
    "href": "slides-midterm1-review.html#pipelines",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Pipelines",
    "text": "Pipelines\n\nPipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\nSimplify the code and improves readability.\nReduce the risk of data leakage by ensuring proper transformation of the training and test sets.\nAutomatically apply transformations in sequence."
  },
  {
    "objectID": "slides-midterm1-review.html#column-transformers",
    "href": "slides-midterm1-review.html#column-transformers",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Column Transformers",
    "text": "Column Transformers\n\nIn what scenarios do we use column transformers?\n\nDifferent transformations for different types of columns (e.g., scaling numerical data, encoding categorical data).\n\nHandle datasets with heterogeneous data types effectively."
  },
  {
    "objectID": "slides-midterm1-review.html#hyperparameter-optimization",
    "href": "slides-midterm1-review.html#hyperparameter-optimization",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Hyperparameter Optimization",
    "text": "Hyperparameter Optimization\n\n\n\n\n\n\n\n\nMethod\nStrengths/Weaknesses\nWhen to use?\n\n\n\n\nNested for loops\n\n\n\n\nGrid search\n\n\n\n\nRandom search"
  },
  {
    "objectID": "slides-midterm1-review.html#classification-metrics",
    "href": "slides-midterm1-review.html#classification-metrics",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Classification Metrics",
    "text": "Classification Metrics\n\n\n\n\n\n\n\n\nMetric\nHow to generate/calculate?\nWhen to use?\n\n\n\n\nAccuracy\n\n\n\n\nPrecision\n\n\n\n\nRecall\n\n\n\n\nF1-score\n\n\n\n\nAP score\n\n\n\n\nAUC"
  },
  {
    "objectID": "slides-midterm1-review.html#regression-metrics",
    "href": "slides-midterm1-review.html#regression-metrics",
    "title": "CPSC 330: Midterm 1 review",
    "section": "Regression Metrics",
    "text": "Regression Metrics\n\n\n\n\n\n\n\n\nMetric\nHow to generate/calculate?\nWhen to use?\n\n\n\n\nMSE\n\n\n\n\nRMSE\n\n\n\n\nr2 score\n\n\n\n\nMAPE"
  }
]