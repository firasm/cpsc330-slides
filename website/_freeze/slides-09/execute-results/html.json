{
  "hash": "641fbf492530bc377156625491442ba1",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"CPSC 330 Lecture 9: Classification Metrics\" \nauthor: \"Firas Moosvi (Slides adapted from Varada Kolhatkar)\"\ndescription: \"Metrics for classification\"\ndescription-short: \"confusion metrics, precision, recall, f1-score, PR curves, AP score, ROC curve, ROC AUC, class imbalance\" \nformat:\n  revealjs:\n    embed-resources: true\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    theme: dracula\n    resources:\n      - data/\n      - img/  \n---\n\n\n\n\n## Announcements\n\n- Learning Log 02 is now out!\n- Reminder: HW4 is due Monday night\n- Reminder: Midterm 1 is this week!\n\n# Recap of Hyperparameter optimization (Demo)\n\n## Group Work: Class Demo & Live Coding\n\nFor this demo, each student should [click this link](https://github.com/new?template_name=lecture08_demo&template_owner=ubc-cpsc330) to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today.\n\n\n\n## ML workflow \n![](img/ml-workflow.png)\n\n## Classification Metrics\n\nAt the end of last class we talked about some of the problems with \"accuracy\", and we brainstormed some possible alternatives, and [saw that there are tonnes of options](https://en.wikipedia.org/wiki/Precision_and_recall#Definition).\n\nToday, let's sift through the noise and develop some intuition about **why** we need classification metrics, and **how** some of them are used.\n\n## Example from StatQuest!\n\nLet's first walk through this [example through StatQuest](https://www.youtube.com/watch?v=4jRBRDbJemM) with obese mice and classifying them using Logistic Regression:\n\n![](img/obese_mice)\n\n[Source: StatQuest](https://www.youtube.com/watch?v=4jRBRDbJemM)\n\n## Activity 1: Create Confusion Matrix\n\n![](img/confusion_matrix.png)\n\n[Source: StatQuest](https://www.youtube.com/watch?v=4jRBRDbJemM)\n\n## Activity 2: Calculate Precision, Recall, Specificity\n\n- Recall (aka Sensitivity in biomedical literature)\n    - TP/(TP+FN)\n\n- Precision\n    - TP/(TP+FP)\n\n- Specificity\n    - TN/(TN+FP)\n\n![](img/calculate_Sen_Spe.png)\n\n## Break!\n\nLet's take a break!\n\n![](img/eva-coffee.png){fig-align=\"center\"}\n\n## Confusion matrix questions \n\nImagine a spam filter model where emails classified as spam are labeled 1 and non-spam emails are labeled 0. If a spam email is incorrectly classified as non-spam, what is this error called?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n## Confusion matrix questions\n\nIn an intrusion detection system, intrusions are identified as 1 and non-intrusive activities as 0. If the system fails to identify an actual intrusion, wrongly categorizing it as non-intrusive, what is this type of error called?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n## Confusion matrix questions\n\nIn a medical test for a disease, diseased states are labeled as 1 and healthy states as 0. If a healthy patient is incorrectly diagnosed with the disease, what is this error known as?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n## iClicker Exercise 9.1\n\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) In medical diagnosis, false positives are more damaging than false negatives (assume \"positive\" means the person has a disease, \"negative\" means they don't).\n- (B) In spam classification, false positives are more damaging than false negatives (assume \"positive\" means the email is spam, \"negative\" means they it's not).\n- (C) If method A gets a higher accuracy than method B, that means its precision is also higher.\n- (D) If method A gets a higher accuracy than method B, that means its recall is also higher.\n\n## Counter examples\n\nMethod A - higher accuracy but lower precision\n\n| Negative | Positive\n| -------- |:-------------:|\n| 90      | 5|\n| 5      | 0|\n\nMethod B - lower accuracy but higher precision\n\n| Negative | Positive\n| -------- |:-------------:|\n| 80      | 15|\n| 0      | 5|\n\n\n## Recap: Confusion matrix\n:::: {.columns}\n:::{.column width=\"80%\"}\n![](img/tp-fp-tn-fn-fraud.png)\n:::\n\n:::{.column width=\"20%\"}\n- TN $\\rightarrow$ True negatives \n- FP $\\rightarrow$ False positives \n- FN $\\rightarrow$ False negatives\n- TP $\\rightarrow$ True positives \n:::\n::::\n\n## Recap: Precision, Recall, F1-Score\n:::: {.columns}\n:::{.column width=\"70%\"}\n![](img/fraud-precision-recall.png)\n:::\n:::{.column width=\"30%\"}\n$$ f1 = 2 \\times \\frac{ precision \\times recall}{precision + recall}$$\n:::\n::::\n\n## Recap: PR curve\n- Calculate precision and recall (TPR) at every possible threshold and graph them. \n- Better choice for highly imbalanced datasets because it focuses on the performance of the positive class. \n\n![](img/pr-curve-example.png)\n\n## Demo: PR curve\n\n[Google's Machine Learning Modules](https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall)\n\n## Recap: ROC curve \n- Calculate the true positive rate (TPR) and false positive rate (FPR) ($\\frac{FP}{FP + TN}$) at every possible thresholding and graph TPR over FPR. \n- Good choice when the datasets are roughly balanced. \n![](img/roc-example.png)\n![](img/roc-curve-example.png)\n\n## Recap: ROC Curve\n\n- Not a great choice when there is an extreme imbalance because FPR can remain relatively low even if the number of false positives is high, simply because the number of negatives is very large.  \n$$ FPR  = \\frac{FP}{FP + TN}$$ \n- The area under the ROC curve (AUC) represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative.\n\n## Questions for you \n\n- What's the difference between the average precision (AP) score and F1-score? \n- Which model would you pick? \n\n![](img/pr-curve-which-model.png)\n\n## Questions for you {.smaller}\n:::: {.columns}\n:::{.column width=\"60%\"}\n![](img/roc-baseline.png) \n:::\n:::{.column width=\"40%\"}\n- What's the AUC of a baseline model? \n:::\n::::\n\n[Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n\n## Questions for you {.smaller}\n<!-- \n:::: {.columns}\n:::{.column width=\"60%\"}\n![](img/roc-curve-which-model.png)\n:::\n:::{.column width=\"40%\"}\n- Which model would you pick? \n:::\n:::: -->\n\n## iClicker Exercise 9.2\n\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) If we increase the classification threshold, both true and false positives are likely to decrease.\n- (B) If we increase the classification threshold, both true and false negatives are likely to decrease.\n- (C) Lowering the classification threshold generally increases the modelâ€™s recall.  \n- (D) Raising the classification threshold can improve the precision of the model if it effectively reduces the number of false positives without significantly affecting true positives.\n\n## Dealing with class imbalance\n\n- Under sampling \n- Oversampling \n- `class weight=\"balanced\"` (preferred method for this course)\n- SMOTE\n\n## ROC AUC questions\n\nConsider the points A, B, and C in the following diagram, each representing a threshold. Which threshold would you pick in each scenario?\n\n:::: {.columns}\n\n:::{.column width=\"50%\"}\n![](img/auc_abc.png)\n:::\n\n:::{.column width=\"50%\"}\n\n- (A) If false positives (false alarms) are highly costly\n- (B) If false positives are cheap and false negatives (missed true positives) highly costly\n- (C) If the costs are roughly equivalent\n:::\n::::\n\n[Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n\n",
    "supporting": [
      "slides-09_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}