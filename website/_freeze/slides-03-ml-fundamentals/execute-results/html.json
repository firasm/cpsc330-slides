{
  "hash": "b4ecb2d75be9250d260d9051aca790e7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Lecture 3: ML fundamentals'\nauthor: \"Firas Moosvi (Slides adapted from Varada Kolhatkar)\"\ndescription: Supervised Machine Learning Fundamentals\ndescription-short: 'generalization, data splitting, overfitting, underfitting, the fundamental tradeoff, the golden rule'\nformat:\n  revealjs:\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    resources:\n      - data/\n      - img/\n---\n\n\n## Announcements \n\n- Homework 2 (hw2) has been released (Due: Sept 16, 11:59pm)\n  - You are welcome to broadly discuss it with your classmates but final answers and submissions must be your own.\n  - Group submissions are not allowed for this assignment.\n- Advice on keeping up with the material\n  - Practice!\n  - Make sure you run the lecture notes on your laptop and experiment with the code. \n  - Start early on homework assignments.\n\n- If you are still on the waitlist, it’s your responsibility to keep up with the material and submit assignments.\n- Last day to drop without a W standing: **Sept 16, 2023**\n\n## Recap\n\n- Importance of generalization in supervised machine learning\n- Data splitting as a way to approximate generalization error\n- Train, test, validation, deployment data\n- Overfitting, underfitting, the fundamental tradeoff, and the golden rule.\n- Cross-validation\n\n## Recap\n\nA typical sequence of steps to train supervised machine learning models\n\n- training the model on the train split\n- tuning hyperparamters using the validation split\n- checking the generalization performance on the test split\n\n## iClicker 3.1\n\nClicker cloud join link: [https://join.iclicker.com/VYFJ](https://join.iclicker.com/VYFJ)\n\nSelect all of the following statements which are TRUE.\n\n- (A) A decision tree model with no depth (the default `max_depth` in sklearn) is likely to perform very well on the deployment data.\n- (B) Data splitting helps us assess how well our model would generalize.\n- (C) Deployment data is only scored once.\n- (D) Validation data could be used for hyperparameter optimization.\n- (E) It’s recommended that data be shuffled before splitting it into train and test sets.\n\n## Additional Resource\n\n::: {#8ceacddb .cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n\n        <iframe\n            width=\"1000\"\n            height=\"650\"\n            src=\"https://mlu-explain.github.io/train-test-validation//\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        \n```\n:::\n:::\n\n\nReference: [MLU-Explain - Data Splitting](https://mlu-explain.github.io/train-test-validation/)\n\n\n## iClicker 3.2\n\nClicker cloud join link: [https://join.iclicker.com/VYFJ](https://join.iclicker.com/VYFJ)\n\nSelect all of the following statements which are TRUE.\n\n(A) $k$-fold cross-validation calls fit $k$ times\n(B) We use cross-validation to get a more robust estimate of model performance.\n(C) If the mean train accuracy is much higher than the mean cross-validation accuracy it’s likely to be a case of overfitting.\n(D) The fundamental tradeoff of ML states that as training error goes down, validation error goes up.\n(E) A decision stump on a complicated classification problem is likely to underfit.\n\n## Additional Resource\n\n::: {#69bbae72 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n\n        <iframe\n            width=\"1000\"\n            height=\"650\"\n            src=\"https://mlu-explain.github.io/cross-validation/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        \n```\n:::\n:::\n\n\nReference: [MLU-Explain - Cross Validation](https://mlu-explain.github.io/cross-validation/)\n\n## Group Work: Class Demo & Live Coding\n\nFor this demo, each student should [click this link](https://github.com/new?template_name=lecture3_demo&template_owner=ubc-cpsc330) to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today.\n\n<br>\n<br>\n<br>\n\nIf you really don't want to create a repo,\n\n- Navigate to the `cpsc330-2024W1` repo\n- run `git pull` to pull the latest files in the course repo\n- Look for the demo file here: `lectures/102-Firas-lectures/class_demos/`.\n\n",
    "supporting": [
      "slides-03-ml-fundamentals_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}