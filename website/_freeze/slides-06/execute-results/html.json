{
  "hash": "084f785bfdd46c3cac9b1a6b2b1da14b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 6: Column transformer and text features\"\nauthor: \"Firas Moosvi (Slides adapted from Varada Kolhatkar)\"\ndescription: \"Column transformer and introduction to text features\"\ndescription-short: \"Preprocessing and sklearn pipelines\"\nformat:\n  revealjs:\n    embed-resources: true\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    theme: dracula\n    resources:\n      - data/\n      - img/  \n---\n\n\n\n\n<!-- \n## Announcements \n\n- Lecture recordings for the first two weeks have been made available - See Piazza.\n- My Office Hours\n- HW3 is due next week Tuesday, Oct 1st, 11:59 pm. \n  - You can work in pairs for this assignment. \n -->\n\n<!-- \n## Quick Correction on Exercise 5.3\n\n> I accidentally said *only D is true*, but **B** is also true!\n\nSelect all of the following statements which are TRUE.\n\n- (A) You can have scaling of numeric features, one-hot encoding of categorical features, and scikit-learn estimator within a single pipeline.\n- (B) Once you have a scikit-learn pipeline object with an estimator as the last step, you can call fit, predict, and score on it.\n- (C) You can carry out data splitting within scikit-learn pipeline.\n- (D) We have to be careful of the order we put each transformation and model in a pipeline.\n- -->\n\n\n\n# Recap: Preprocessing mistakes\n\n## Data \n\n::: {#c3626b93 .cell execution_count=2}\n``` {.python .cell-code}\nX, y = make_blobs(n_samples=100, centers=3, random_state=12, cluster_std=5) # make synthetic data\nX_train_toy, X_test_toy, y_train_toy, y_test_toy = train_test_split(\n    X, y, random_state=5, test_size=0.4) # split it into training and test sets\n# Visualize the training data\nplt.scatter(X_train_toy[:, 0], X_train_toy[:, 1], label=\"Training set\", s=60)\nplt.scatter(\n    X_test_toy[:, 0], X_test_toy[:, 1], color=mglearn.cm2(1), label=\"Test set\", s=60\n)\nplt.legend(loc=\"upper right\")\n```\n\n::: {.cell-output .cell-output-display}\n![](slides-06_files/figure-revealjs/cell-3-output-1.png){}\n:::\n:::\n\n\n## ❌ Bad ML 1\n- What's wrong with the approach below? \n\n::: {#252d4553 .cell execution_count=3}\n``` {.python .cell-code}\nscaler = StandardScaler() # Creating a scalert object \nscaler.fit(X_train_toy) # Calling fit on the training data \ntrain_scaled = scaler.transform(\n    X_train_toy\n)  # Transforming the training data using the scaler fit on training data\n\nscaler = StandardScaler()  # Creating a separate object for scaling test data\nscaler.fit(X_test_toy)  # Calling fit on the test data\ntest_scaled = scaler.transform(\n    X_test_toy\n)  # Transforming the test data using the scaler fit on test data\n\nknn = KNeighborsClassifier()\nknn.fit(train_scaled, y_train_toy)\nprint(f\"Training score: {knn.score(train_scaled, y_train_toy):.2f}\")\nprint(f\"Test score: {knn.score(test_scaled, y_test_toy):.2f}\") # misleading scores\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining score: 0.63\nTest score: 0.60\n```\n:::\n:::\n\n\n## Scaling train and test data separately\n\n::: {#a3f160d7 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](slides-06_files/figure-revealjs/cell-5-output-1.png){}\n:::\n:::\n\n\n## ❌ Bad ML 2 \n- What's wrong with the approach below? \n\n::: {#28ce09ef .cell execution_count=5}\n``` {.python .cell-code}\n# join the train and test sets back together\nXX = np.vstack((X_train_toy, X_test_toy))\n\nscaler = StandardScaler()\nscaler.fit(XX)\nXX_scaled = scaler.transform(XX)\n\nXX_train = XX_scaled[:X_train_toy.shape[0]]\nXX_test = XX_scaled[X_train_toy.shape[0]:]\n\nknn = KNeighborsClassifier()\nknn.fit(XX_train, y_train_toy)\nprint(f\"Training score: {knn.score(XX_train, y_train_toy):.2f}\")  # Misleading score\nprint(f\"Test score: {knn.score(XX_test, y_test_toy):.2f}\")  # Misleading score\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining score: 0.63\nTest score: 0.55\n```\n:::\n:::\n\n\n## ❌ Bad ML 3\n\n- What's wrong with the approach below? \n\n::: {#c93ccd7d .cell execution_count=6}\n``` {.python .cell-code}\nknn = KNeighborsClassifier()\n\nscaler = StandardScaler()\nscaler.fit(X_train_toy)\nX_train_scaled = scaler.transform(X_train_toy)\nX_test_scaled = scaler.transform(X_test_toy)\ncross_val_score(knn, X_train_scaled, y_train_toy)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\narray([0.25      , 0.5       , 0.58333333, 0.58333333, 0.41666667])\n```\n:::\n:::\n\n\n::: {.notes}\nSpeaker notes go here.\n:::\n\n::: {.scroll-container style=\"overflow-y: scroll; height: 500px;\"}\n## Improper preprocessing\n\n::: {#288bd871 .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](slides-06_files/figure-revealjs/cell-8-output-1.png){}\n:::\n:::\n\n\n:::\n\n::: {.scroll-container style=\"overflow-y: scroll; height: 500px;\"}\n## Proper preprocessing\n\n::: {#2fbe79c6 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](slides-06_files/figure-revealjs/cell-9-output-1.png){}\n:::\n:::\n\n\n:::\n\n## Recap: `sklearn` Pipelines\n\n- Pipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\n- Simplify the code and improves readability.\n- Reduce the risk of data leakage by ensuring proper transformation of the training and test sets.\n- Automatically apply transformations in sequence.\n- **Example:**\n  - Chaining a `StandardScaler` with a `KNeighborsClassifier` model.\n\n::: {#6b6f1c4a .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.pipeline import make_pipeline\n\npipe_knn = make_pipeline(StandardScaler(), KNeighborsClassifier())\n\n# Correct way to do cross validation without breaking the golden rule. \ncross_val_score(pipe_knn, X_train_toy, y_train_toy) \n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([0.25      , 0.5       , 0.5       , 0.58333333, 0.41666667])\n```\n:::\n:::\n\n\n## Group Work: Class Demo & Live Coding\n\nFor this demo, each student should [click this link](https://github.com/new?template_name=lecture06_demo&template_owner=ubc-cpsc330) to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today.\n\n## `sklearn`'s `ColumnTransformer` \n\n- Use ColumnTransformer to build all our transformations together into one object \n\n![](img/column-transformer.png)\n\n- Use a column transformer with sklearn pipelines. \n\n",
    "supporting": [
      "slides-06_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}