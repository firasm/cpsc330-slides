{
  "hash": "65e9eb3735d373665f8c62b5ae59c972",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 7: Linear models\"\nauthor: \"Firas Moosvi (Slides adapted from Varada Kolhatkar)\"\ndescription: \"Linear regression, logistic regression\"\ndescription-short: \"Linear regression, logistic regression, prediction probabilities, sigmoid, interpretation of coefficients\"\nformat:\n  revealjs:\n    embed-resources: true\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    theme: dracula\n    resources:\n      - data/\n      - img/  \n---\n\n\n\n\n\n## Announcements\n\n- Learning Log 01 is due on Sunday!\n- HW3 is due tonight!\n- HW4 is due Monday night\n- Reminder about Midterm 1 next week!\n\n<!-- \n- Remember Monday September 30th is a holiday, National Day for Truth and Reconciliation\n    - I encourage you to spend some reflecting on the Indigenous peoples of Canada. I invite you to [explore the Beyond 94 project which tracks the progress of the 94 calls to action.](https://www.cbc.ca/newsinteractives/beyond-94)\n\n![](img/beyond94.png){.nostretch fig-align=\"center\" width=\"600px\"}\n -->\n\n<!-- \n## Announcements\n\n- HW3 is due next week Tuesday, Oct 1st, 11:59 pm. \n    - You can work in pairs for this assignment. \n -->\n\n# Recap of pre-processing\n\n## (iClicker) Exercise 6.1\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) You could carry out cross-validation by passing a `ColumnTransformer` object to `cross_validate`.\n- (B) After applying column transformer, the order of the columns in the transformed data has to be the same as the order of the columns in the original data.\n- (C) After applying a column transformer, the transformed data is always going to be of different shape than the original data.\n- (D) When you call `fit_transform` on a `ColumnTransformer` object, you get a numpy ndarray.\n\n::: {.notes}\niClicker 6.1\n\nA. False, column transfer to pipeline. There is no estimator attached to ColumnTransfer\n\nB. False, numeric, binary, ordinal, categorical etc‚Ä¶Can also use this to remove columns\n\nC. False, often it will be different, but not always\n\nD. True, just an ndarray, not a data frame\n:::\n\n## Notes on preprocessing \n- There is no one-size-fits-all solution in data preprocessing, and decisions often involve a degree of subjectivity. \n  - Exploratory data analysis and domain knowledge inform these decisions\n- Always consider the specific goals of your project when deciding how to encode features. \n\n## Alternative methods for scaling (Reference)\n- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n  - Good choice when the column follows a normal distribution or a distribution somewhat like a normal distribution.\n- [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html): Transform each feature to a desired range. Appropriate when \n  - Good choice for features such as human age, where there is a fixed range of values and the feature is uniformly distributed across the range\n- [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html): Works on rows rather than columns. Normalize examples individually to unit norm.\n  - Good choice for frequency-type data \n- [Log scaling](https://scikit-learn.org/stable/modules/preprocessing.html#custom-transformers)\n  - Good choice for features such as ratings per movies (power law distribution; a few movies have lots of ratings but most movies have very few ratings) \n- ...\n\n## Ordinal encoding vs. One-hot encoding\n\n- Ordinal Encoding: Encodes categorical features as an integer array.\n- One-hot Encoding: Creates binary columns for each category‚Äôs presence.\n- Sometimes how we encode a specific feature depends upon the context.  \n\n## Ordinal encoding vs. One-hot encoding (Reference)\n- Consider **weather** feature and its four categories: Sunny (‚òÄÔ∏è), Cloudy (üå•Ô∏è), Rainy (‚õàÔ∏è), Snowy (‚ùÑÔ∏è)\n- Which encoding would you use in each of the following scenarios? \n  - **Predicting traffic volume** \n  - **Predicting severity of weather-related road incidents** \n\n## Ordinal encoding vs. One-hot encoding (Reference)\n- Consider **weather** feature and its four categories: Sunny (‚òÄÔ∏è), Cloudy (üå•Ô∏è), Rainy (‚õàÔ∏è), Snowy (‚ùÑÔ∏è)\n- **Predicting traffic volume:** Using one-hot encoding would make sense here because the impact of different weather conditions on traffic volume does not necessarily follow a clear order and different weather conditions could have very distinct effects.\n- **Predicting severity of weather-related road incidents:** An ordinal encoding might be more appropriate if you define your weather categories from least to most severe as this could correlate directly with the likelihood or severity of incidents.\n\n## `handle_unknown = \"ignore\"` of `OneHotEncoder` \n- Use `handle_unknown='ignore'` with `OneHotEncoder` to safely ignore unseen categories during transform.\n\n::: {.callout-note}\n\n## Question for you to consider in your Group\nHow would you determine whether it is reasonable or not to set\n\n`handle_unknown = \"ignore\"`?\n:::\n\n## `handle_unknown = \"ignore\"` of `OneHotEncoder` \n- Example 1: Suppose you are building a model to predict customer behavior (e.g., purchase likelihood) based on features like `location`, `device_type`, and `product_category`. During training, you have observed a set of categories for `product_category`, but in the future, new product categories might be added.\n\n<br>\n\n- Example 2: You‚Äôre building a model to predict disease diagnosis based on symptoms, where each symptom is categorized (e.g., fever, headache, nausea).\n\n## `handle_unknown = \"ignore\"` of `OneHotEncoder` \n- Reasonable use: When unseen categories are less likely to impact the model's prediction accuracy (e.g., product categories in e-commerce), and you prefer to avoid breaking the model.\n- Not-so-reasonable use: When unseen categories could provide critical new information that could significantly alter predictions (e.g., in medical diagnostics), ignoring them could result in a poor or dangerous outcome.\n\n## `drop=\"if_binary\"` argument of OneHotEncoder (Reference)\n\n- drop='if_binary' argument in OneHotEncoder:\n- Reduces redundancy by dropping one of the columns if the feature is binary.\n\n## Categorical variables with too many categories\n- Strategies for categorical variables with too many categories:\n    - Dimensionality reduction techniques\n    - Bucketing categories into ‚Äòothers‚Äô\n    - Clustering or grouping categories manually \n    - Only considering top-N categories \n    - ...\n\n## Dealing with text features \n- Preprocessing text to fit into machine learning models using text vectorization.\n- Bag of words representation \n![](img/bag-of-words.png)\n\n## `sklearn` `CountVectorizer`\n- Use `scikit-learn`‚Äôs `CountVectorizer` to encode text data\n- `CountVectorizer`: Transforms text into a matrix of token counts\n- Important parameters:\n  - `max_features`: Control the number of features used in the model \n  - `max_df`, `min_df`: Control document frequency thresholds\n  - `ngram_range`: Defines the range of n-grams to be extracted\n  - `stop_words`: Enables the removal of common words that are typically uninformative in most applications, such as ‚Äúand‚Äù, ‚Äúthe‚Äù, etc.\n\n## Incorporating text features in a machine learning pipeline\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\ntext_pipeline = make_pipeline(\n    CountVectorizer(),\n    SVC()\n)\n```\n\n## (iClicker) Exercise 6.2\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\nSelect all of the following statements which are TRUE.\n\n- (A) `handle_unknown=\"ignore\"` would treat all unknown categories equally.\n- (B) As you increase the value for `max_features` hyperparameter of `CountVectorizer` the training score is likely to go up.\n- (C) Suppose you are encoding text data using `CountVectorizer`. If you encounter a word in the validation or the test split that's not available in the training data, we'll get an error.\n- (D) In the code below, inside `cross_validate`, each fold might have slightly different number of features (columns) in the fold.\n\n```python\npipe = (CountVectorizer(), SVC())\ncross_validate(pipe, X_train, y_train)\n```\n\n------------------------------------------------\n\n\n\n## Recap: Dealing with text features \n- Preprocessing text to fit into machine learning models using text vectorization.\n- Bag of words representation \n![](img/bag-of-words.png)\n\n## Recap: `sklearn` `CountVectorizer`\n- Use `scikit-learn`‚Äôs `CountVectorizer` to encode text data\n- `CountVectorizer`: Transforms text into a matrix of token counts\n- Important parameters:\n  - `max_features`: Control the number of features used in the model \n  - `max_df`, `min_df`: Control document frequency thresholds\n  - `ngram_range`: Defines the range of n-grams to be extracted\n  - `stop_words`: Enables the removal of common words that are typically uninformative in most applications, such as ‚Äúand‚Äù, ‚Äúthe‚Äù, etc.\n\n## Recap: Incorporating text features in a machine learning pipeline\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\ntext_pipeline = make_pipeline(\n    CountVectorizer(),\n    SVC()\n)\n```\n\n# Linear models \n\n:::: {.columns}\n\n:::{.column width=\"45%\"}\n- Linear models make an assumption that the relationship between `X` and `y` is linear. \n- In this case, with only one feature, our model is a straight line.\n- What do we need to represent a line?\n  - Slope ($w_1$): Determines the angle of the line.\n  - Y-intercept ($w_0$): Where the line crosses the y-axis.\n\n:::\n\n::: {.column width=\"55%\"}\n\n::: {#327acb73 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](slides-07_files/figure-revealjs/cell-3-output-1.png){}\n:::\n:::\n\n\n- Making predictions\n  - $\\hat{y} = w_1 \\times \\text{# hours studied} + w_0$\n\n:::\n\n::::\n\n## `Ridge` vs. `LinearRegression`\n- Ordinary linear regression is sensitive to **multicolinearity** and overfitting\n- Multicolinearity: Overlapping and redundant features. Most of the real-world datasets have colinear features.   \n- Linear regression may produce large and unstable coefficients in such cases. \n- `Ridge` adds a parameter to control the complexity of a model. Finds a line that balances fit and prevents overly large coefficients.\n\n## When to use what?\n- `LinearRegression`\n  - When interpretability is key, and no multicollinearity exists\n- `Ridge` \n  - When you have **multicollinearity** (highly correlated features).\n  - When you want to prevent **overfitting** in linear models.\n  - When **model stability** is important.\n- **In this course, we'll use `Ridge`.**\n\n## Logistic regression \n- Suppose your target is binary: pass or fail \n- Logistic regression is used for such binary classification tasks.  \n- Logistic regression predicts a probability that the given example belongs to a particular class.\n- It uses **Sigmoid function** to map any real-valued input into a value between 0 and 1, representing the probability of a specific outcome.\n- A threshold (usually 0.5) is applied to the predicted probability to decide the final class label.  \n\n## Logistic regression: Decision boundary \n\n:::: {.columns}\n\n:::{.column width=\"60%\"}\n\n::: {#6848557b .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](slides-07_files/figure-revealjs/cell-4-output-1.png){}\n:::\n:::\n\n\n:::\n:::{.column width=\"40%\"}\n- The decision boundary is the point on the x-axis where the corresponding predicted probability on the y-axis is 0.5. \n:::\n\n::::\n\n## Parametric vs. non-Parametric models (high-level)\n- Imagine you are training a logistic regression model. For each of the following scenarios, identify how many parameters (weights and biases) will be learned.\n- Scenario 1: 100 features and 1,000 examples\n- Scenario 2: 100 features and 1 million examples\n\n## Parametric vs. non-Parametric models (high-level)\n:::: {.columns}\n\n:::{.column width=\"50%\"}\n#### Parametric\n- Examples: Logistic regression, linear regression, linear SVM  \n- Models with a fixed number of parameters, regardless of the dataset size\n- Simple, computationally efficient, less prone to overfitting\n- Less flexible, may not capture complex relationships\n:::\n\n:::{.column width=\"50%\"}\n#### Non parametric\n- Examples: KNN, SVM RBF, Decision tree with no specific depth specified \n- Models where the number of parameters grows with the dataset size. They do not assume a fixed form for the functions being learned. \n- Flexible, can adapt to complex patterns\n- Computationally expensive, risk of overfitting with noisy data\n:::\n\n::::\n\n## (iClicker) Exercise 7.1\n\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\nSelect all of the following statements which are TRUE.\n\n- (A) Increasing the hyperparameter alpha of Ridge is likely to decrease model complexity.\n- (B) Ridge can be used with datasets that have multiple features.\n- (C) With Ridge, we learn one coefficient per training example.\n- (D) If you train a linear regression model on a 2-dimensional problem (2 features), the model will learn 3 parameters: one for each feature and one for the bias term.\n\n## (iClicker) Exercise 7.2\n\n**iClicker cloud join link: [https://join.iclicker.com/YJHS](https://join.iclicker.com/YJHS)**\n\nSelect all of the following statements which are TRUE.\n\n- (A) Increasing logistic regression‚Äôs `C` hyperparameter increases model complexity.\n- (B) The raw output score can be used to calculate the probability score for a given prediction.\n- (C) For linear classifier trained on $d$ features, the decision boundary is a $d-1$-dimensional hyperplane.\n- (D) A linear model is likely to be uncertain about the data points close to the decision boundary.\n\n## Group Work: Class Demo & Live Coding\n\nFor this demo, each student should [click this link](https://github.com/new?template_name=lecture07_demo&template_owner=ubc-cpsc330) to create a new repo in their accounts, then clone that repo locally to follow along with the demo from today.\n\n",
    "supporting": [
      "slides-07_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}